{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 521.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18_with_dropout\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 8217.17it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 8679.12it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 8458.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute alignment indicates number: 106 label diff indicates number: 12 confidence diff indicates number: 16 high distance number: 97\n"
     ]
    }
   ],
   "source": [
    "####### dropout resnet18 vs without dropout\n",
    "#### \n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "\n",
    "CLEAN_PATH = \"/home/yifan/dataset/resnet18_with_dropout/pairflip/cifar10/0/\"\n",
    "REF_PATH = \"/home/yifan/dataset/clean/pairflip/cifar10/0\"\n",
    "\n",
    "\n",
    "ENCODER_DIMS=[512,256,256,256,256,2]\n",
    "DECODER_DIMS= [2,256,256,256,256,512]\n",
    "VIS_MODEL_NAME = 'vis'\n",
    "\n",
    "DEVICE='cuda:1'\n",
    "########## initulize reference data and target data\n",
    "from alignment.data_preprocess import DataInit\n",
    "REF_EPOCH = 200\n",
    "TAR_EPOCH = 200\n",
    "ref_datainit = DataInit(REF_PATH,REF_PATH,REF_EPOCH)\n",
    "tar_datainit = DataInit(CLEAN_PATH,CLEAN_PATH,TAR_EPOCH)\n",
    "ref_model, ref_provider, ref_train_data, ref_prediction, ref_prediction_res, ref_scores = ref_datainit.getData()\n",
    "tar_model, tar_provider, tar_train_data, tar_prediction, tar_prediction_res, tar_scores = tar_datainit.getData()\n",
    "\n",
    "\n",
    "from alignment.ReferenceGenerator import ReferenceGenerator\n",
    "gen = ReferenceGenerator(ref_provider=ref_provider, tar_provider=tar_provider,REF_EPOCH=REF_EPOCH,TAR_EPOCH=TAR_EPOCH,ref_model=ref_model,tar_model=tar_model,DEVICE=DEVICE)\n",
    "\n",
    "absolute_alignment_indicates,predict_label_diff_indicates,predict_confidence_Diff_indicates,high_distance_indicates = gen.subsetClassify(18,0.8,0.3,0.05)\n",
    "\n",
    "\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "\n",
    "I = np.eye(512)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "vis = visualizer(ref_provider, I,I, np.dot(ref_provider.train_representation(TAR_EPOCH),I), projector, 200,[0,1],'tab10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5297, 0.6251, 0.5927, 0.5306, 0.5791, 0.5667, 0.5847, 0.5635, 0.5695,\n",
      "        0.5763])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设X和Y是高维数据，每一行代表一个样本\n",
    "X = torch.Tensor(ref_train_data)\n",
    "Y = torch.Tensor(tar_train_data)\n",
    "\n",
    "# 计算每行样本之间的皮尔逊相关系数\n",
    "corr = F.cosine_similarity(X, Y, dim=1)\n",
    "\n",
    "# 打印前10个样本的相关系数\n",
    "print(corr[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tar_train_data\n",
    "Y = ref_train_data\n",
    "# 计算X和Y的均值和标准差\n",
    "X_mean, X_std = np.mean(X, axis=0), np.std(X, axis=0)\n",
    "Y_mean, Y_std = np.mean(Y, axis=0), np.std(Y, axis=0)\n",
    "\n",
    "# 将X缩放到Y的尺度\n",
    "X_scaled = (X - X_mean) * (Y_std / X_std) + Y_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.5511, 0.6504, 0.6205, 0.5520, 0.6021, 0.5994, 0.6097, 0.5858, 0.5937,\n",
      "        0.5988])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 假设X和Y是高维数据，每一行代表一个样本\n",
    "X = torch.Tensor(X_scaled)\n",
    "Y = torch.Tensor(Y)\n",
    "\n",
    "# 计算每行样本之间的皮尔逊相关系数\n",
    "corr = F.cosine_similarity(X, Y, dim=1)\n",
    "\n",
    "# 打印前10个样本的相关系数\n",
    "print(corr[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKA between absolute alignmnet subset is: 0.8234975187095028\n"
     ]
    }
   ],
   "source": [
    "from CKA_utils.CKA import CKA, CudaCKA\n",
    "np_cka = CKA()\n",
    "# indicates = np.random.choice(aligned, size=10, replace=False)\n",
    "indicates = np.random.choice(np.arange(5000), size=1000, replace=False)\n",
    "print('CKA between absolute alignmnet subset is:',np_cka.kernel_CKA(X[indicates],Y[indicates]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKA between absolute alignmnet subset is: 0.8269703859772014\n"
     ]
    }
   ],
   "source": [
    "from CKA_utils.CKA import CKA, CudaCKA\n",
    "np_cka = CKA()\n",
    "# indicates = np.random.choice(aligned, size=10, replace=False)\n",
    "indicates = np.random.choice(np.arange(5000), size=1000, replace=False)\n",
    "print('CKA between absolute alignmnet subset is:',np_cka.kernel_CKA(X_scaled[indicates],Y[indicates]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AlignVisAutoEncoder.autoencoder import SimpleAutoencoder\n",
    "from AlignVisAutoEncoder.data import DataLoaderInit\n",
    "input_dim = 512\n",
    "output_dim = 512\n",
    "\n",
    "autoencoder = SimpleAutoencoder(input_dim,output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(\"/home/yifan/projects/deepdebugertool/DLVisDebugger/AlignVisAutoEncoder/checkpoints/dropout_no_f_epoch_200.pth\")\n",
    "autoencoder.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Y into X's space\n",
    "encoded_Y = autoencoder.encoder(torch.Tensor(Y))\n",
    "encoded_Y = encoded_Y.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKA between absolute alignmnet subset is: 0.5663528197091249\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from CKA_utils.CKA import CKA, CudaCKA\n",
    "np_cka = CKA()\n",
    "# indicates = np.random.choice(aligned, size=10, replace=False)\n",
    "indicates = np.random.choice(np.arange(5000), size=1000, replace=False)\n",
    "print('CKA between absolute alignmnet subset is:',np_cka.kernel_CKA(X[indicates],encoded_Y[indicates]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CKA between absolute alignmnet subset is: 0.7490385480257218\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from CKA_utils.CKA import CKA, CudaCKA\n",
    "np_cka = CKA()\n",
    "# indicates = np.random.choice(aligned, size=10, replace=False)\n",
    "indicates = np.random.choice(np.arange(5000), size=1000, replace=False)\n",
    "print('CKA between absolute alignmnet subset is:',np_cka.kernel_CKA(Y[indicates],encoded_Y[indicates]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "deepdebugger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
