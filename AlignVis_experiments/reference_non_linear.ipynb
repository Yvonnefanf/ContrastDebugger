{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 8299.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 8204.82it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 8723.88it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 8616.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute alignment indicates number: 3 label diff indicates number: 508 confidence diff indicates number: 8 high distance number: 10210\n"
     ]
    }
   ],
   "source": [
    "####### dropout resnet18 vs without dropout\n",
    "#### \n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "\n",
    "CLEAN_PATH = \"/home/yifan/experiments/backdoor/resnet18_CIFAR10_target_5/experiment1\"\n",
    "REF_PATH = \"/home/yifan/dataset/clean/pairflip/cifar10/0\"\n",
    "\n",
    "\n",
    "ENCODER_DIMS=[512,256,256,256,256,2]\n",
    "DECODER_DIMS= [2,256,256,256,256,512]\n",
    "VIS_MODEL_NAME = 'vis'\n",
    "\n",
    "DEVICE='cuda:0'\n",
    "########## initulize reference data and target data\n",
    "from alignment.data_preprocess import DataInit\n",
    "REF_EPOCH = 200\n",
    "TAR_EPOCH = 200\n",
    "ref_datainit = DataInit(REF_PATH,REF_PATH,REF_EPOCH)\n",
    "tar_datainit = DataInit(CLEAN_PATH,CLEAN_PATH,TAR_EPOCH)\n",
    "ref_model, ref_provider, ref_train_data, ref_prediction, ref_prediction_res, ref_scores = ref_datainit.getData()\n",
    "tar_model, tar_provider, tar_train_data, tar_prediction, tar_prediction_res, tar_scores = tar_datainit.getData()\n",
    "\n",
    "\n",
    "from alignment.ReferenceGenerator import ReferenceGenerator\n",
    "gen = ReferenceGenerator(ref_provider=ref_provider, tar_provider=tar_provider,REF_EPOCH=REF_EPOCH,TAR_EPOCH=TAR_EPOCH,ref_model=ref_model,tar_model=tar_model,DEVICE=DEVICE)\n",
    "\n",
    "absolute_alignment_indicates,predict_label_diff_indicates,predict_confidence_Diff_indicates,high_distance_indicates = gen.subsetClassify(mes_val_for_diff=18,mes_val_for_same=0.8,conf_val_for_diff=0.3,conf_val_for_same=0.05)\n",
    "\n",
    "\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "\n",
    "I = np.eye(512)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "vis = visualizer(ref_provider, I,I, np.dot(ref_provider.train_representation(TAR_EPOCH),I), projector, 200,[0,1],'tab10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.Tensor(ref_train_data)\n",
    "Y = torch.Tensor(tar_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X can be approximately linearly transformed into Y.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Calculate the mean of each dataset\n",
    "X_mean = torch.mean(X, dim=0)\n",
    "Y_mean = torch.mean(Y, dim=0)\n",
    "\n",
    "# Calculate the covariance matrices for X and Y\n",
    "X_cov = torch.matmul((X - X_mean).T, X - X_mean)\n",
    "Y_cov = torch.matmul((Y - Y_mean).T, Y - Y_mean)\n",
    "\n",
    "# Compute the Singular Value Decomposition (SVD) of the covariance matrices\n",
    "Ux, Sx, Vx = torch.svd(X_cov)\n",
    "Uy, Sy, Vy = torch.svd(Y_cov)\n",
    "\n",
    "# Check if the eigenvectors of X and Y are the same\n",
    "if torch.allclose(Ux, Uy):\n",
    "    # If the eigenvectors are the same, you can transform X to Y by multiplying X by Vx.T and then Y by Ux.\n",
    "    A = torch.matmul(Vx.T, Ux)\n",
    "    X_transformed = torch.matmul(X, A)\n",
    "    Y_transformed = torch.matmul(Y, Ux)\n",
    "    print('X can be linearly transformed into Y.')\n",
    "else:\n",
    "    # If the eigenvectors are not the same, you can find the closest linear transformation using Principal Component Analysis (PCA).\n",
    "    pca = PCA(n_components=X.shape[1])\n",
    "    pca.fit(X.detach().numpy())\n",
    "    A = torch.matmul(torch.tensor(pca.components_).T, Uy)\n",
    "    X_transformed = torch.matmul(X, A)\n",
    "    Y_transformed = torch.matmul(Y, Uy)\n",
    "    print('X can be approximately linearly transformed into Y.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cka(X, Y, n_samples=2000, reg=1e-8):\n",
    "    \"\"\"\n",
    "    Computes the Centered Kernel Alignment (CKA) between two sets of embeddings X and Y.\n",
    "\n",
    "    Args:\n",
    "    X: A PyTorch tensor of shape (n_samples, n_features) representing the embeddings of the first set.\n",
    "    Y: A PyTorch tensor of shape (n_samples, n_features) representing the embeddings of the second set.\n",
    "    n_samples: The number of samples to use for computing the CKA score. Default is 2000.\n",
    "    reg: A small regularization term to add to the diagonal of the Gram matrices. Default is 1e-8.\n",
    "\n",
    "    Returns:\n",
    "    The CKA score between X and Y.\n",
    "    \"\"\"\n",
    "\n",
    "    # Randomly select a subset of the embeddings\n",
    "    idx = torch.randperm(X.shape[0])[:n_samples]\n",
    "    X = X[idx]\n",
    "    Y = Y[idx]\n",
    "\n",
    "    # Compute the centered Gram matrices of X and Y\n",
    "    X_centered = X - torch.mean(X, dim=0, keepdim=True)\n",
    "    Y_centered = Y - torch.mean(Y, dim=0, keepdim=True)\n",
    "    X_gram = torch.matmul(X_centered.T, X_centered)\n",
    "    Y_gram = torch.matmul(Y_centered.T, Y_centered)\n",
    "\n",
    "    # Apply whitening transformation to the centered Gram matrices\n",
    "    X_gram_diag = torch.diag(X_gram)\n",
    "    Y_gram_diag = torch.diag(Y_gram)\n",
    "    X_gram_sqrt = torch.inverse(torch.sqrt(X_gram + reg * torch.eye(X_gram.shape[0], device=X.device)))\n",
    "    Y_gram_sqrt = torch.inverse(torch.sqrt(Y_gram + reg * torch.eye(Y_gram.shape[0], device=Y.device)))\n",
    "    X_whitened = torch.matmul(torch.matmul(X_centered, X_gram_sqrt), torch.matmul(X_gram_sqrt, X_centered.T))\n",
    "    Y_whitened = torch.matmul(torch.matmul(Y_centered, Y_gram_sqrt), torch.matmul(Y_gram_sqrt, Y_centered.T))\n",
    "\n",
    "    # Compute the CKA score\n",
    "    return torch.trace(torch.matmul(X_whitened, Y_whitened)) / torch.sqrt(torch.trace(torch.matmul(X_whitened, X_whitened)) * torch.trace(torch.matmul(Y_whitened, Y_whitened)))\n",
    "\n",
    "\n",
    "# # Define two sets of embeddings X and Y with the same dimensions\n",
    "# X = np.random.randn(100, 50)\n",
    "# Y = np.random.randn(100, 50)\n",
    "\n",
    "# Check that the SVD of X and Y is not enough to ensure the same CKA score\n",
    "Ux, Sx, Vx = np.linalg.svd(X)\n",
    "Uy, Sy, Vy = np.linalg.svd(Y)\n",
    "if np.allclose(Ux, Uy):\n",
    "    print(\"SVD of X and Y is not enough to ensure the same CKA score\")\n",
    "\n",
    "# Compute the CKA score between X and Y\n",
    "cka_score = cka(X, Y)\n",
    "\n",
    "# Print the CKA score\n",
    "print(\"CKA score between X and Y:\", cka_score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "deepdebugger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
