{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 480.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NET resnet18_with_dropout\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 7914.62it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 8661.62it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 7875.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute alignment indicates number: 106 label diff indicates number: 12 confidence diff indicates number: 16 high distance number: 97\n"
     ]
    }
   ],
   "source": [
    "####### dropout resnet18 vs without dropout\n",
    "#### \n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import numpy as np\n",
    "\n",
    "CLEAN_PATH = \"/home/yifan/dataset/resnet18_with_dropout/pairflip/cifar10/0/\"\n",
    "REF_PATH = \"/home/yifan/dataset/clean/pairflip/cifar10/0\"\n",
    "\n",
    "\n",
    "ENCODER_DIMS=[512,256,256,256,256,2]\n",
    "DECODER_DIMS= [2,256,256,256,256,512]\n",
    "VIS_MODEL_NAME = 'vis'\n",
    "\n",
    "DEVICE='cuda:0'\n",
    "########## initulize reference data and target data\n",
    "from alignment.data_preprocess import DataInit\n",
    "REF_EPOCH = 200\n",
    "TAR_EPOCH = 200\n",
    "ref_datainit = DataInit(REF_PATH,REF_PATH,REF_EPOCH)\n",
    "tar_datainit = DataInit(CLEAN_PATH,CLEAN_PATH,TAR_EPOCH)\n",
    "ref_model, ref_provider, ref_train_data, ref_prediction, ref_prediction_res, ref_scores = ref_datainit.getData()\n",
    "tar_model, tar_provider, tar_train_data, tar_prediction, tar_prediction_res, tar_scores = tar_datainit.getData()\n",
    "\n",
    "\n",
    "from alignment.ReferenceGenerator import ReferenceGenerator\n",
    "gen = ReferenceGenerator(ref_provider=ref_provider, tar_provider=tar_provider,REF_EPOCH=REF_EPOCH,TAR_EPOCH=TAR_EPOCH,ref_model=ref_model,tar_model=tar_model,DEVICE=DEVICE)\n",
    "\n",
    "absolute_alignment_indicates,predict_label_diff_indicates,predict_confidence_Diff_indicates,high_distance_indicates = gen.subsetClassify(mes_val_for_diff=18,mes_val_for_same=0.8,conf_val_for_diff=0.3,conf_val_for_same=0.05)\n",
    "\n",
    "\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "\n",
    "I = np.eye(512)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "vis = visualizer(ref_provider, I,I, np.dot(ref_provider.train_representation(TAR_EPOCH),I), projector, 200,[0,1],'tab10')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ref_train_data\n",
    "Y = tar_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "def gram_linear(x):\n",
    "    \"\"\"Compute Gram (kernel) matrix for a linear kernel.\"\"\"\n",
    "    return torch.matmul(x, x.t())\n",
    "\n",
    "def center_gram(K):\n",
    "    \"\"\"Center a symmetric Gram matrix.\"\"\"\n",
    "    n = K.shape[0]\n",
    "    unit = torch.ones([n, n], device=K.device) / n\n",
    "    return K - torch.matmul(K, unit) - torch.matmul(unit, K) + torch.matmul(torch.matmul(unit, K), unit)\n",
    "\n",
    "def cka(X, Y):\n",
    "    \"\"\"Compute CKA between two matrices.\"\"\"\n",
    "    X_centered = center_gram(gram_linear(X))\n",
    "    Y_centered = center_gram(gram_linear(Y))\n",
    "    X_normalized = torch.linalg.inv(torch.sqrt(torch.diag(torch.diag(X_centered))))\n",
    "    Y_normalized = torch.linalg.inv(torch.sqrt(torch.diag(torch.diag(Y_centered))))\n",
    "    X_normalized_centered = torch.matmul(torch.matmul(X_normalized, X_centered), X_normalized)\n",
    "    Y_normalized_centered = torch.matmul(torch.matmul(Y_normalized, Y_centered), Y_normalized)\n",
    "    cka = torch.trace(torch.matmul(X_normalized_centered, Y_normalized_centered)) / torch.sqrt(torch.trace(torch.matmul(X_normalized_centered, X_normalized_centered)) * torch.trace(torch.matmul(Y_normalized_centered, Y_normalized_centered)))\n",
    "    return cka.item()\n",
    "# Define a neural network architecture\n",
    "class MyNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(512, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "# Create a neural network and an optimizer\n",
    "net = MyNet()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "# Train the neural network to minimize the CKA loss\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    X_trans = net(torch.from_numpy(X).float())\n",
    "    Y_torch = torch.from_numpy(Y).float()\n",
    "    cka_loss = 1 - cka(X_trans, Y_torch)\n",
    "    mse_loss = torch.mean(torch.pow(X_trans - X, 2))\n",
    "    loss = 0.5 * cka_loss + 0.5 + mse_loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(\"Epoch {}: loss={}\".format(epoch+1, loss))\n",
    "\n",
    "# Compute the CKA value between X_trans and Y\n",
    "X_trans = net(torch.from_numpy(X).float())\n",
    "Y_torch = torch.from_numpy(Y).float()\n",
    "cka_value = cka(X_trans, Y_torch)\n",
    "print(\"CKA value between X_trans and Y: {}\".format(cka_value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "deepdebugger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
