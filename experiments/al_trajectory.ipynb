{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "from scipy.special import softmax\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.SingleVisualizationModel import SingleVisualizationModel\n",
    "from singleVis.data import DenseActiveLearningDataProvider\n",
    "from singleVis.projector import DenseALProjector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/active_learning/random/resnet18/MNIST\"\n",
    "GPU_ID = \"0\"\n",
    "epoch_num = 20\n",
    "iteration = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(CONTENT_PATH)\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n"
     ]
    }
   ],
   "source": [
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "BASE_ITERATION =config[\"BASE_ITERATION\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "LAMBDA = VISUALIZATION_PARAMETER[\"LAMBDA\"]\n",
    "S_LAMBDA = VISUALIZATION_PARAMETER[\"S_LAMBDA\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "INIT_NUM = VISUALIZATION_PARAMETER[\"INIT_NUM\"]\n",
    "ALPHA = VISUALIZATION_PARAMETER[\"ALPHA\"]\n",
    "BETA = VISUALIZATION_PARAMETER[\"BETA\"]\n",
    "MAX_HAUSDORFF = VISUALIZATION_PARAMETER[\"MAX_HAUSDORFF\"]\n",
    "HIDDEN_LAYER = VISUALIZATION_PARAMETER[\"HIDDEN_LAYER\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "T_N_EPOCHS = VISUALIZATION_PARAMETER[\"T_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "# define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "model = SingleVisualizationModel(input_dims=512, output_dims=2, units=256, hidden_layer=HIDDEN_LAYER)\n",
    "\n",
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))\n",
    "data_provider = DenseActiveLearningDataProvider(CONTENT_PATH, net, BASE_ITERATION, epoch_num, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "projector = DenseALProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=\"al_hybrid\", device=DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.visualizer import DenseALvisualizer\n",
    "vis = DenseALvisualizer(data_provider, projector, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no train labels saved for Iteration 3\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2978789/325672354.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_representation_lb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_labels_lb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_provider\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mvis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msavefig_cus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data/projects-xianglin/git_space/DLVisDebugger/singleVis/data.py\u001b[0m in \u001b[0;36mtrain_labels_lb\u001b[0;34m(self, epoch)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"no train labels saved for Iteration {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mtraining_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtraining_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_representation_ulb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "data = data_provider.train_representation_lb(iteration, epoch_num)\n",
    "labels = data_provider.train_labels_lb(iteration)\n",
    "pred = data_provider.get_pred(iteration, epoch_num, data).argmax(1)\n",
    "vis.savefig_cus(iteration, epoch_num, data, pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 5256.83it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = data_provider.train_representation(iteration, epoch_num)\n",
    "pred = data_provider.get_pred(iteration, epoch_num, samples)\n",
    "confidence = np.amax(softmax(pred, axis=1), axis=1)\n",
    "uncertainty = 1-confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.zeros((epoch_num, LEN, 512))\n",
    "for i in range(1, epoch_num+1, 1):\n",
    "    samples[i-1] = data_provider.train_representation(iteration, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load the visualization model in iteration 1 for range (1,17]...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Successfully load the visualization model in iteration 1 for range (17,50]...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n",
      "Same range as current visualization model...\n"
     ]
    }
   ],
   "source": [
    "embeddings_2d = np.zeros((epoch_num, LEN, 2))\n",
    "for e in range(1, epoch_num+1, 1):\n",
    "    embeddings_2d[e-1] = projector.batch_project(iteration, e, samples[e-1])\n",
    "embeddings_2d = np.transpose(embeddings_2d, [1,0,2])\n",
    "labels = data_provider.train_labels(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(CONTENT_PATH, \"Model\", \"Iteration_{}\".format(iteration),\"trajectory_embeddings.npy\")\n",
    "np.save(path,embeddings_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(CONTENT_PATH, \"Model\", \"Iteration_{}\".format(iteration),\"trajectory_embeddings.npy\")\n",
    "embeddings_2d = np.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 512), (60000,), (60000, 20, 2))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape,uncertainty.shape, embeddings_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove label data\n",
    "lb_idxs = data_provider.get_labeled_idx(iteration)\n",
    "ulb_idxs = data_provider.get_unlabeled_idx(LEN, lb_idxs)\n",
    "\n",
    "ulb_uncertainty = uncertainty[ulb_idxs]\n",
    "ulb_trajectory = embeddings_2d[ulb_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.trajectory_manager import TrajectoryManager, FeedbackTrajectoryManager, Recommender\n",
    "import pickle\n",
    "tm = Recommender(ulb_uncertainty, ulb_trajectory, 30, period=50,metric=\"a\")#20.50,80\n",
    "tm.clustered()\n",
    "with open(os.path.join(CONTENT_PATH, \"Model\",\"Iteration_{}\".format(iteration), 'sample_recommender.pkl'), 'wb') as f:\n",
    "    pickle.dump(tm, f, pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(os.path.join(CONTENT_PATH, \"Model\",\"Iteration_{}\".format(iteration), 'sample_recommender.pkl'), 'rb') as f:\n",
    "    tm = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:00<00:00, 4109.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "617 0.012854166666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = data_provider.train_representation(iteration, epoch_num)\n",
    "labels = data_provider.train_labels(iteration)\n",
    "pred = data_provider.get_pred(iteration, epoch_num, data).argmax(1)\n",
    "wrong_pred_idx = np.argwhere(pred!=labels).squeeze()\n",
    "ulb_wrong = np.intersect1d(wrong_pred_idx, ulb_idxs)\n",
    "print(len(ulb_wrong), len(ulb_wrong)/len(ulb_idxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_rate = 0.1\n",
    "remain_rate = 1-ignore_rate\n",
    "test_len = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sampling init\n",
      "Success Rate:\t0.5006\n"
     ]
    }
   ],
   "source": [
    "# random\n",
    "print(\"Random sampling init\")\n",
    "s_rate = list()\n",
    "pool = np.array(ulb_idxs)\n",
    "for _ in range(10000):\n",
    "    s_idxs = np.random.choice(pool,size=test_len,replace=False)\n",
    "    # print(len(np.intersect1d(s_idxs, ulb_wrong)), len(s_idxs))\n",
    "    s_rate.append(len(np.intersect1d(s_idxs, ulb_wrong))/test_len)\n",
    "    # pool = np.setdiff1d(pool, s_idxs)\n",
    "print(\"Success Rate:\\t{:.4f}\".format(sum(s_rate)/len(s_rate)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random sampling feedback\n",
      "Success Rate:\t0.0060\n",
      "[0.0, 0.02, 0.0, 0.0, 0.0, 0.0, 0.0, 0.02, 0.0, 0.02]\n"
     ]
    }
   ],
   "source": [
    "# random\n",
    "print(\"Random sampling feedback\")\n",
    "s_rate = list()\n",
    "pool = np.array(ulb_idxs)\n",
    "for _ in range(10):\n",
    "    s_idxs = np.random.choice(pool,size=test_len,replace=False)\n",
    "    # print(len(np.intersect1d(s_idxs, ulb_wrong)), len(s_idxs))\n",
    "    s_rate.append(len(np.intersect1d(s_idxs, ulb_wrong))/test_len)\n",
    "    pool = np.setdiff1d(pool, s_idxs)\n",
    "print(\"Success Rate:\\t{:.4f}\".format(sum(s_rate)/len(s_rate)))\n",
    "print(s_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB sampling initialization:\n",
      "Init success Rate:\t0.0156\n"
     ]
    }
   ],
   "source": [
    "print(\"TB sampling initialization:\")\n",
    "init_rate = list()\n",
    "for _ in range(10000):\n",
    "    correct = np.array([]).astype(np.int32)\n",
    "    wrong = np.array([]).astype(np.int32)\n",
    "    map_ulb =ulb_idxs.tolist()\n",
    "    \n",
    "    map_acc_idxs = np.array([map_ulb.index(i) for i in correct]).astype(np.int32)\n",
    "    map_rej_idxs = np.array([map_ulb.index(i) for i in wrong]).astype(np.int32)\n",
    "\n",
    "    suggest_idxs, _ = tm.sample_batch_init(map_acc_idxs, map_rej_idxs, test_len)\n",
    "    suggest_idxs = ulb_idxs[suggest_idxs]\n",
    "\n",
    "    correct = np.intersect1d(suggest_idxs, ulb_wrong)\n",
    "    wrong = np.setdiff1d(suggest_idxs, correct)\n",
    "    init_rate.append(len(correct)/test_len)\n",
    "    # print(len(correct),test_len)\n",
    "print(\"Init success Rate:\\t{:.4f}\".format(sum(init_rate)/len(init_rate)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TB sampling:\n",
      "Success Rate:\t0.4267\n",
      "[0.02, 0.64, 0.66, 0.44, 0.42, 0.46, 0.46, 0.34, 0.4]\n"
     ]
    }
   ],
   "source": [
    "# kernel regression\n",
    "print(\"TB sampling:\")\n",
    "s_rate = list()\n",
    "for _ in range(9):\n",
    "    map_acc_idxs = np.array([map_ulb.index(i) for i in correct]).astype(np.int32)\n",
    "    map_rej_idxs = np.array([map_ulb.index(i) for i in wrong]).astype(np.int32)\n",
    "    suggest_idxs,_ = tm.sample_batch(map_acc_idxs, map_rej_idxs, test_len)\n",
    "    suggest_idxs = ulb_idxs[suggest_idxs]\n",
    "    c = np.intersect1d(np.intersect1d(suggest_idxs, ulb_idxs), ulb_wrong)\n",
    "    w = np.setdiff1d(suggest_idxs, c)\n",
    "    # print(len(c), test_len)\n",
    "    s_rate.append(len(c) / test_len)\n",
    "    correct = np.concatenate((correct, c), axis=0)\n",
    "    wrong = np.concatenate((wrong, w), axis=0)\n",
    "print(\"Success Rate:\\t{:.4f}\".format(sum(s_rate)/len(s_rate)))\n",
    "print(s_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('SV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa7a9f36e1a1e240450dbe9cc8f6d8df1d5301f36681fb271c44fdd883236b60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
