{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from umap.umap_ import find_ab_params\n",
    "\n",
    "from singleVis.custom_weighted_random_sampler import CustomWeightedRandomSampler\n",
    "from singleVis.SingleVisualizationModel import SingleVisualizationModel\n",
    "from singleVis.losses import SingleVisLoss, UmapLoss, ReconstructionLoss\n",
    "from singleVis.edge_dataset import DataHandler\n",
    "from singleVis.trainer import SingleVisTrainer\n",
    "from singleVis.data import NormalDataProvider\n",
    "import singleVis.config as config\n",
    "from singleVis.eval.evaluator import Evaluator\n",
    "from singleVis.spatial_edge_constructor import kcSpatialEdgeConstructor\n",
    "from singleVis.temporal_edge_constructor import GlobalTemporalEdgeConstructor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONTENT_PATH = \"/home/xianglin/projects/DVI_data/noisy/pairflip/cifar10\"\n",
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/resnet18_cifar10\"\n",
    "# CONTENT_PATH = \"/home/xianglin/projects/DVI_data/resnet18_mnist\"\n",
    "# CONTENT_PATH = \"/home/xianglin/projects/DVI_data/resnet18_fmnist\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(CONTENT_PATH)\n",
    "from config import config\n",
    "\n",
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "PREPROCESS = config[\"VISUALIZATION\"][\"PREPROCESS\"]\n",
    "GPU_ID = config[\"GPU\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "LAMBDA = VISUALIZATION_PARAMETER[\"LAMBDA\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "INIT_NUM = VISUALIZATION_PARAMETER[\"INIT_NUM\"]\n",
    "ALPHA = VISUALIZATION_PARAMETER[\"ALPHA\"]\n",
    "BETA = VISUALIZATION_PARAMETER[\"BETA\"]\n",
    "MAX_HAUSDORFF = VISUALIZATION_PARAMETER[\"MAX_HAUSDORFF\"]\n",
    "HIDDEN_LAYER = VISUALIZATION_PARAMETER[\"HIDDEN_LAYER\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "T_N_EPOCHS = VISUALIZATION_PARAMETER[\"T_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "SEGMENTS = VISUALIZATION_PARAMETER[\"SEGMENTS\"]\n",
    "RESUME_SEG = VISUALIZATION_PARAMETER[\"RESUME_SEG\"]\n",
    "\n",
    "# define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "if PREPROCESS:\n",
    "    data_provider.initialize(LEN//10, l_bound=L_BOUND)\n",
    "\n",
    "model = SingleVisualizationModel(input_dims=512, output_dims=2, units=256, hidden_layer=HIDDEN_LAYER)\n",
    "negative_sample_rate = 5\n",
    "min_dist = .1\n",
    "_a, _b = find_ab_params(1.0, min_dist)\n",
    "umap_loss_fn = UmapLoss(negative_sample_rate, DEVICE, _a, _b, repulsion_strength=1.0)\n",
    "recon_loss_fn = ReconstructionLoss(beta=1.0)\n",
    "criterion = SingleVisLoss(umap_loss_fn, recon_loss_fn, lambd=LAMBDA)\n",
    "\n",
    "# Resume from a check point\n",
    "if RESUME_SEG in range(len(SEGMENTS)):\n",
    "    prev_epoch = SEGMENTS[RESUME_SEG][0]\n",
    "    with open(os.path.join(data_provider.content_path, \"selected_idxs\", \"selected_{}.json\".format(prev_epoch)), \"r\") as f:\n",
    "        prev_selected = json.load(f)\n",
    "        \n",
    "    INIT_NUM = len(prev_selected)\n",
    "    save_model_path = os.path.join(data_provider.model_path, \"tnn_hybrid_{}.pth\".format(RESUME_SEG))\n",
    "    save_model = torch.load(save_model_path, map_location=torch.device(\"cpu\"))\n",
    "    model.load_state_dict(save_model[\"state_dict\"])\n",
    "    start_point = RESUME_SEG - 1\n",
    "    print(\"Resume from {}-th segment with {} points...\".format(RESUME_SEG, INIT_NUM))\n",
    "else: \n",
    "    prev_selected = np.random.choice(np.arange(LEN), size=INIT_NUM, replace=False)\n",
    "    start_point = len(SEGMENTS)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SingleVisualizationModel(input_dims=512, output_dims=2, units=256, hidden_layer=HIDDEN_LAYER)\n",
    "negative_sample_rate = 5\n",
    "min_dist = .1\n",
    "_a, _b = find_ab_params(1.0, min_dist)\n",
    "umap_loss_fn = UmapLoss(negative_sample_rate, DEVICE, _a, _b, repulsion_strength=1.0)\n",
    "recon_loss_fn = ReconstructionLoss(beta=1.0)\n",
    "criterion = SingleVisLoss(umap_loss_fn, recon_loss_fn, lambd=LAMBDA)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.01, weight_decay=1e-5)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=4, gamma=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = os.path.join(data_provider.content_path, \"img\")\n",
    "os.system(\"mkdir -p {}\".format(save_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize img from one specified segment\n",
    "trainer = SingleVisTrainer(model, criterion=criterion, optimizer=optimizer, lr_scheduler=lr_scheduler, edge_loader=None, DEVICE=DEVICE)\n",
    "trainer.load(file_path=os.path.join(data_provider.model_path,\"tnn_hybrid_{}.pth\".format(4)))\n",
    "\n",
    "from singleVis.visualizer import visualizer\n",
    "vis = visualizer(data_provider, trainer.model, 200, 10, CLASSES)\n",
    "for i in range(155,200,1):\n",
    "    vis.savefig(i, path=os.path.join(save_dir, \"hybrid_{}.png\".format(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate a certain epoch\n",
    "i=20\n",
    "evaluator = Evaluator(data_provider, trainer)\n",
    "evaluator.save_epoch_eval(i, 15, temporal_k=5, save_corrs=False, file_name=\"test_evaluation_hybrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate hybrid epoch\n",
    "from singleVis.backend import find_neighbor_preserving_rate\n",
    "eval_num = 50\n",
    "l = 60000\n",
    "\n",
    "alpha = np.zeros((eval_num, l))\n",
    "delta_x = np.zeros((eval_num, l))\n",
    "\n",
    "trainer.load(file_path=os.path.join(data_provider.model_path,\"tnn_hybrid_{}.pth\".format(2)))\n",
    "trainer.model.eval()\n",
    "\n",
    "for t in range(9,50):\n",
    "    prev_data = data_provider.train_representation(t)\n",
    "    prev_embedding = trainer.model.encoder(\n",
    "        torch.from_numpy(prev_data).to(dtype=torch.float32, device=trainer.DEVICE)).cpu().detach().numpy()\n",
    "\n",
    "    curr_data = data_provider.train_representation(t+1)\n",
    "    curr_embedding = trainer.model.encoder(\n",
    "        torch.from_numpy(curr_data).to(dtype=torch.float32, device=trainer.DEVICE)).cpu().detach().numpy()\n",
    "\n",
    "    alpha_ = find_neighbor_preserving_rate(prev_data, curr_data, n_neighbors=15)\n",
    "    delta_x_ = np.linalg.norm(prev_embedding - curr_embedding, axis=1)\n",
    "\n",
    "    alpha[t-1] = alpha_\n",
    "    delta_x[t-1] = delta_x_\n",
    "\n",
    "trainer.load(file_path=os.path.join(data_provider.model_path,\"tnn_hybrid_{}.pth\".format(1)))\n",
    "trainer.model.eval()\n",
    "\n",
    "for t in range(4,9):\n",
    "    prev_data = data_provider.train_representation(t)\n",
    "    prev_embedding = trainer.model.encoder(\n",
    "        torch.from_numpy(prev_data).to(dtype=torch.float32, device=trainer.DEVICE)).cpu().detach().numpy()\n",
    "\n",
    "    curr_data = data_provider.train_representation(t+1)\n",
    "    curr_embedding = trainer.model.encoder(\n",
    "        torch.from_numpy(curr_data).to(dtype=torch.float32, device=trainer.DEVICE)).cpu().detach().numpy()\n",
    "\n",
    "    alpha_ = find_neighbor_preserving_rate(prev_data, curr_data, n_neighbors=15)\n",
    "    delta_x_ = np.linalg.norm(prev_embedding - curr_embedding, axis=1)\n",
    "\n",
    "    alpha[t-1] = alpha_\n",
    "    delta_x[t-1] = delta_x_\n",
    "\n",
    "trainer.load(file_path=os.path.join(data_provider.model_path,\"tnn_hybrid_{}.pth\".format(0)))\n",
    "trainer.model.eval()\n",
    "\n",
    "for t in range(1,4):\n",
    "    prev_data = data_provider.train_representation(t)\n",
    "    prev_embedding = trainer.model.encoder(\n",
    "        torch.from_numpy(prev_data).to(dtype=torch.float32, device=trainer.DEVICE)).cpu().detach().numpy()\n",
    "\n",
    "    curr_data = data_provider.train_representation(t+1)\n",
    "    curr_embedding = trainer.model.encoder(\n",
    "        torch.from_numpy(curr_data).to(dtype=torch.float32, device=trainer.DEVICE)).cpu().detach().numpy()\n",
    "\n",
    "    alpha_ = find_neighbor_preserving_rate(prev_data, curr_data, n_neighbors=15)\n",
    "    delta_x_ = np.linalg.norm(prev_embedding - curr_embedding, axis=1)\n",
    "\n",
    "    alpha[t-1] = alpha_\n",
    "    delta_x[t-1] = delta_x_\n",
    "\n",
    "from singleVis.eval.evaluate import evaluate_proj_temporal_perseverance_corr\n",
    "val_corr, corr_std = evaluate_proj_temporal_perseverance_corr(alpha, delta_x)\n",
    "val_corr, corr_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynndescent import NNDescent\n",
    "def hausdorff_d(curr_data, prev_data):\n",
    "\n",
    "    # number of trees in random projection forest\n",
    "    n_trees = min(64, 5 + int(round((curr_data.shape[0]) ** 0.5 / 20.0)))\n",
    "    # max number of nearest neighbor iters to perform\n",
    "    n_iters = max(5, int(round(np.log2(curr_data.shape[0]))))\n",
    "    # distance metric\n",
    "    metric = \"euclidean\"\n",
    "    # get nearest neighbors\n",
    "    nnd = NNDescent(\n",
    "        curr_data,\n",
    "        n_neighbors=1,\n",
    "        metric=metric,\n",
    "        n_trees=n_trees,\n",
    "        n_iters=n_iters,\n",
    "        max_candidates=10,\n",
    "        verbose=False\n",
    "    )\n",
    "    _, dists1 = nnd.query(prev_data,k=1)\n",
    "    m1 = dists1.mean()\n",
    "    return m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_data = data_provider.train_representation(200)\n",
    "prev_data = data_provider.train_representation(199)\n",
    "hausdorff_d(curr_data=curr_data, prev_data=prev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist\n",
    "d = np.zeros(19)\n",
    "for curr_epoch in range(20,1,-1):\n",
    "    curr_data = data_provider.test_representation(curr_epoch)\n",
    "    prev_data = data_provider.test_representation(curr_epoch-1)\n",
    "    d[curr_epoch-2] = hausdorff_d(curr_data=curr_data, prev_data=prev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[2:].sum(),d[:3].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmnist\n",
    "d = np.zeros(49)\n",
    "for curr_epoch in range(50,1,-1):\n",
    "    curr_data = data_provider.test_representation(curr_epoch)\n",
    "    prev_data = data_provider.test_representation(curr_epoch-1)\n",
    "    d[curr_epoch-2] = hausdorff_d(curr_data=curr_data, prev_data=prev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[9:].sum(),d[4:10].sum(),d[:5].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cifar10\n",
    "d = np.zeros(200)\n",
    "for curr_epoch in range(200, 1, -1):\n",
    "    curr_data = data_provider.train_representation(curr_epoch)\n",
    "    prev_data = data_provider.train_representation(curr_epoch-1)\n",
    "    d[curr_epoch-2] = hausdorff_d(curr_data=curr_data, prev_data=prev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[:7].sum(), d[6:16].sum(), d[15:43].sum(), d[42:200].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# symmetric cifar10\n",
    "d = np.zeros(199)\n",
    "for curr_epoch in range(200,1,-1):\n",
    "    curr_data = data_provider.train_representation(curr_epoch)\n",
    "    prev_data = data_provider.train_representation(curr_epoch-1)\n",
    "    d[curr_epoch-2] = hausdorff_d(curr_data=curr_data, prev_data=prev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[155:].sum(),d[60:156].sum(), d[:61].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairflip cifar10\n",
    "d = np.zeros(199)\n",
    "for curr_epoch in range(200,1,-1):\n",
    "    curr_data = data_provider.train_representation(curr_epoch)\n",
    "    prev_data = data_provider.train_representation(curr_epoch-1)\n",
    "    d[curr_epoch-2] = hausdorff_d(curr_data=curr_data, prev_data=prev_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[135:].sum(),d[48:136].sum(), d[:49].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tried methods\n",
    "1. normed distance between epochs\n",
    "2. the jaccard similarity between consecutive epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overlapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "dataset = \"symmetric\"\n",
    "path = \"/home/xianglin/projects/DVI_data/noisy/{}/cifar10/clean_label.json\".format(dataset)\n",
    "with open(path, \"r\") as f:\n",
    "    clean_label = json.load(f)\n",
    "path = \"/home/xianglin/projects/DVI_data/noisy/{}/cifar10/noisy_label.json\".format(dataset)\n",
    "with open(path, \"r\") as f:\n",
    "    noisy_label = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(data_provider.model_path, \"tnn_hybrid_{}.pth\".format(4))\n",
    "save_model = torch.load(save_model_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(save_model[\"state_dict\"])\n",
    "model.to(device=torch.device(\"cuda:{}\".format(GPU_ID)))\n",
    "\n",
    "samples = np.zeros((160, 50000, 512))\n",
    "for i in range(160):\n",
    "    samples[i] = data_provider.train_representation(i+41)\n",
    "\n",
    "embeddings_2d = np.zeros((50000, 160, 2))\n",
    "for i in range(50000):\n",
    "    embedding_2d = model.encoder(torch.from_numpy(samples[:,i,:]).to(device=DEVICE, dtype=torch.float)).cpu().detach().numpy()\n",
    "    embeddings_2d[i] = embedding_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(data_provider.model_path, \"tnn_hybrid_{}.pth\".format(3))\n",
    "save_model = torch.load(save_model_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(save_model[\"state_dict\"])\n",
    "model.to(device=torch.device(\"cuda:{}\".format(GPU_ID)))\n",
    "\n",
    "samples = np.zeros((10, 50000, 512))\n",
    "for i in range(10):\n",
    "    samples[i] = data_provider.train_representation(i+31)\n",
    "\n",
    "embeddings_2d_2 = np.zeros((50000, 10, 2))\n",
    "for i in range(50000):\n",
    "    embedding_2d = model.encoder(torch.from_numpy(samples[:,i,:]).to(device=DEVICE, dtype=torch.float)).cpu().detach().numpy()\n",
    "    embeddings_2d_2[i] = embedding_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(data_provider.model_path, \"tnn_hybrid_{}.pth\".format(2))\n",
    "save_model = torch.load(save_model_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(save_model[\"state_dict\"])\n",
    "model.to(device=torch.device(\"cuda:{}\".format(GPU_ID)))\n",
    "\n",
    "samples = np.zeros((10, 50000, 512))\n",
    "for i in range(10):\n",
    "    samples[i] = data_provider.train_representation(i+21)\n",
    "\n",
    "embeddings_2d_3 = np.zeros((50000, 10, 2))\n",
    "for i in range(50000):\n",
    "    embedding_2d = model.encoder(torch.from_numpy(samples[:,i,:]).to(device=DEVICE, dtype=torch.float)).cpu().detach().numpy()\n",
    "    embeddings_2d_3[i] = embedding_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(data_provider.model_path, \"tnn_hybrid_{}.pth\".format(1))\n",
    "save_model = torch.load(save_model_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(save_model[\"state_dict\"])\n",
    "model.to(device=torch.device(\"cuda:{}\".format(GPU_ID)))\n",
    "\n",
    "samples = np.zeros((10, 50000, 512))\n",
    "for i in range(10):\n",
    "    samples[i] = data_provider.train_representation(i+11)\n",
    "\n",
    "embeddings_2d_4 = np.zeros((50000, 10, 2))\n",
    "for i in range(50000):\n",
    "    embedding_2d = model.encoder(torch.from_numpy(samples[:,i,:]).to(device=DEVICE, dtype=torch.float)).cpu().detach().numpy()\n",
    "    embeddings_2d_4[i] = embedding_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(data_provider.model_path, \"tnn_hybrid_{}.pth\".format(0))\n",
    "save_model = torch.load(save_model_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(save_model[\"state_dict\"])\n",
    "model.to(device=torch.device(\"cuda:{}\".format(GPU_ID)))\n",
    "\n",
    "samples = np.zeros((10, 50000, 512))\n",
    "for i in range(10):\n",
    "    samples[i] = data_provider.train_representation(i+1)\n",
    "\n",
    "embeddings_2d_5 = np.zeros((50000, 10, 2))\n",
    "for i in range(50000):\n",
    "    embedding_2d = model.encoder(torch.from_numpy(samples[:,i,:]).to(device=DEVICE, dtype=torch.float)).cpu().detach().numpy()\n",
    "    embeddings_2d_5[i] = embedding_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.concatenate((embeddings_2d_5, embeddings_2d_4), axis=1)\n",
    "embedding = np.concatenate((embedding, embeddings_2d_3), axis=1)\n",
    "embedding = np.concatenate((embedding, embeddings_2d_2), axis=1)\n",
    "embedding = np.concatenate((embedding, embeddings_2d), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(data_provider.model_path, \"tnn_hybrid_{}.pth\".format(2))\n",
    "save_model = torch.load(save_model_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(save_model[\"state_dict\"])\n",
    "model.to(device=torch.device(\"cuda:{}\".format(GPU_ID)))\n",
    "\n",
    "samples = np.zeros((44, 50000, 512))\n",
    "for i in range(44):\n",
    "    samples[i] = data_provider.train_representation(i+156)\n",
    "\n",
    "embeddings_2d = np.zeros((50000, 44, 2))\n",
    "for i in range(50000):\n",
    "    embedding_2d = model.encoder(torch.from_numpy(samples[:,i,:]).to(device=DEVICE, dtype=torch.float)).cpu().detach().numpy()\n",
    "    embeddings_2d[i] = embedding_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(data_provider.model_path, \"tnn_hybrid_{}.pth\".format(1))\n",
    "save_model = torch.load(save_model_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(save_model[\"state_dict\"])\n",
    "model.to(device=torch.device(\"cuda:{}\".format(GPU_ID)))\n",
    "\n",
    "samples = np.zeros((96, 50000, 512))\n",
    "for i in range(96):\n",
    "    samples[i] = data_provider.train_representation(i+61)\n",
    "\n",
    "embeddings_2d_1 = np.zeros((50000, 96, 2))\n",
    "for i in range(50000):\n",
    "    embedding_2d = model.encoder(torch.from_numpy(samples[:,i,:]).to(device=DEVICE, dtype=torch.float)).cpu().detach().numpy()\n",
    "    embeddings_2d_1[i] = embedding_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = os.path.join(data_provider.model_path, \"tnn_hybrid_{}.pth\".format(0))\n",
    "save_model = torch.load(save_model_path, map_location=torch.device(\"cpu\"))\n",
    "model.load_state_dict(save_model[\"state_dict\"])\n",
    "model.to(device=torch.device(\"cuda:{}\".format(GPU_ID)))\n",
    "\n",
    "samples = np.zeros((60, 50000, 512))\n",
    "for i in range(60):\n",
    "    samples[i] = data_provider.train_representation(i+1)\n",
    "\n",
    "embeddings_2d_2 = np.zeros((50000, 60, 2))\n",
    "for i in range(50000):\n",
    "    embedding_2d = model.encoder(torch.from_numpy(samples[:,i,:]).to(device=DEVICE, dtype=torch.float)).cpu().detach().numpy()\n",
    "    embeddings_2d_2[i] = embedding_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = np.concatenate((embeddings_2d_2, embeddings_2d_1), axis=1)\n",
    "embedding = np.concatenate((embedding, embeddings_2d), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = embedding.reshape(len(embedding), -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_label = np.array(noisy_label)\n",
    "clean_label = np.array(clean_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import umap.umap_ as umap\n",
    "from sklearn.manifold import TSNE \n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import Birch, KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cls_num in range(10):\n",
    "    cls = np.argwhere(np.array(noisy_label)==cls_num).squeeze()\n",
    "    high_data = embedding[cls].reshape(len(cls), -1)\n",
    "\n",
    "\n",
    "    reducer = umap.UMAP(n_components=2)\n",
    "    em_2d = reducer.fit_transform(high_data)\n",
    "\n",
    "    # from sklearn.manifold import TSNE\n",
    "    # embedding = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(high_data)\n",
    "\n",
    "    brc = Birch(n_clusters=2)\n",
    "    brc.fit(em_2d)\n",
    "\n",
    "    labels = brc.labels_\n",
    "    centroid = brc.subcluster_centers_\n",
    "    centroid_labels = brc.subcluster_labels_\n",
    "    # clean 1, noise 0\n",
    "    bin = np.bincount(labels)\n",
    "    if bin[0] > bin[1]:\n",
    "        centroid_labels = np.abs(centroid_labels-1)\n",
    "        labels = np.abs(labels-1)\n",
    "\n",
    "    plt.clf()\n",
    "    plt.scatter(\n",
    "        em_2d[:, 0],\n",
    "        em_2d[:, 1],\n",
    "        s=1,\n",
    "        c=clean_label[cls],\n",
    "        cmap=\"tab10\")\n",
    "    plt.scatter(\n",
    "        brc.subcluster_centers_[:, 0],\n",
    "        brc.subcluster_centers_[:, 1],\n",
    "        s=5,\n",
    "        c='black')\n",
    "    plt.show()\n",
    "    plt.clf()\n",
    "    plt.scatter(\n",
    "        em_2d[:, 0],\n",
    "        em_2d[:, 1],\n",
    "        s=1,\n",
    "        c=brc.labels_,\n",
    "        cmap=\"Pastel2\")\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(centroid[centroid_labels==1])\n",
    "    dists, indices = nbrs.kneighbors(centroid[centroid_labels==1])\n",
    "    suspicious = (dists[:, -1]/ dists[:, 1])>1.8\n",
    "\n",
    "    cleans = centroid[centroid_labels==1]\n",
    "    noises = centroid[centroid_labels==0]\n",
    "    plt.scatter(\n",
    "        cleans[:, 0],\n",
    "        cleans[:, 1],\n",
    "        s=5,\n",
    "        c='r')\n",
    "    plt.scatter(\n",
    "        noises[:, 0],\n",
    "        noises[:, 1],\n",
    "        s=5,\n",
    "        c='black')\n",
    "    plt.scatter(\n",
    "        cleans[suspicious][:, 0],\n",
    "        cleans[suspicious][:, 1],\n",
    "        s=5,\n",
    "        c='g')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(CONTENT_PATH, \"embedding.npy\"), embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('SV')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aa7a9f36e1a1e240450dbe9cc8f6d8df1d5301f36681fb271c44fdd883236b60"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
