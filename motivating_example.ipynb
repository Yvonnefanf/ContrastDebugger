{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from umap.umap_ import find_ab_params\n",
    "import time\n",
    "\n",
    "from singleVis.SingleVisualizationModel import SingleVisualizationModel\n",
    "from singleVis.losses import SingleVisLoss, UmapLoss, ReconstructionLoss\n",
    "from singleVis.edge_dataset import DataHandler\n",
    "from singleVis.trainer import SingleVisTrainer\n",
    "from singleVis.data import DataProvider\n",
    "from singleVis.visualizer import visualizer\n",
    "\n",
    "from singleVis.backend import fuzzy_complex, boundary_wise_complex, construct_step_edge_dataset, \\\n",
    "    construct_temporal_edge_dataset, get_attention, construct_temporal_edge_dataset2\n",
    "import singleVis.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = \"cifar10\"\n",
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/TemporalExp/resnet18_{}\".format(DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully load visualization mdoel\n"
     ]
    }
   ],
   "source": [
    "\n",
    "LEN = config.dataset_config[DATASET][\"TRAINING_LEN\"]\n",
    "LAMBDA = config.dataset_config[DATASET][\"LAMBDA\"]\n",
    "\n",
    "# define hyperparameters\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "EPOCH_NUMS = config.training_config[\"EPOCH_NUM\"]\n",
    "TIME_STEPS = config.training_config[\"TIME_STEPS\"]\n",
    "TEMPORAL_PERSISTENT = config.training_config[\"TEMPORAL_PERSISTENT\"]\n",
    "NUMS = config.training_config[\"NUMS\"]    # how many epoch should we go through for one pass\n",
    "PATIENT = config.training_config[\"PATIENT\"]\n",
    "\n",
    "content_path = CONTENT_PATH\n",
    "sys.path.append(content_path)\n",
    "\n",
    "from Model.model import *\n",
    "net = resnet18()\n",
    "classes = (\"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "\n",
    "data_provider = DataProvider(content_path, net, 1, TIME_STEPS, 1, split=-1, device=DEVICE, verbose=1)\n",
    "\n",
    "model = SingleVisualizationModel(input_dims=512, output_dims=2, units=256)\n",
    "negative_sample_rate = 5\n",
    "min_dist = .1\n",
    "_a, _b = find_ab_params(1.0, min_dist)\n",
    "umap_loss_fn = UmapLoss(negative_sample_rate, _a, _b, repulsion_strength=1.0)\n",
    "recon_loss_fn = ReconstructionLoss(beta=1.0)\n",
    "criterion = SingleVisLoss(umap_loss_fn, recon_loss_fn, lambd=LAMBDA)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=.01, weight_decay=1e-5)\n",
    "\n",
    "trainer = SingleVisTrainer(model, criterion, optimizer, edge_loader=None, DEVICE=DEVICE)\n",
    "trainer.load(file_path=os.path.join(data_provider.model_path,\"temporal_SV.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_data = data_provider.train_representation(6)\n",
    "curr_data = data_provider.train_representation(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "dists = np.linalg.norm(prev_data - curr_data, axis=1)\n",
    "dists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.model.eval()\n",
    "import torch\n",
    "\n",
    "prev_data = torch.from_numpy(prev_data).to(device=data_provider.DEVICE, dtype=torch.float)\n",
    "prev_embedding = trainer.model.encoder(prev_data).detach().cpu().numpy()\n",
    "\n",
    "curr_data = torch.from_numpy(curr_data).to(device=data_provider.DEVICE, dtype=torch.float)\n",
    "curr_embedding = trainer.model.encoder(curr_data).detach().cpu().numpy()\n",
    "\n",
    "embedding_dists = np.linalg.norm(prev_embedding-curr_embedding, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4304724884634175, 0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats.stats import pearsonr\n",
    "corr = pearsonr(dists, embedding_dists)\n",
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_B(preds, threshold):\n",
    "    \"\"\"\n",
    "    given N points' prediction (N, class_num), we evaluate whether they are \\delta-boundary points or not\n",
    "\n",
    "    Please check the formal definition of \\delta-boundary from our paper DVI\n",
    "    :param preds: ndarray, (N, class_num), the output of model prediction before softmax layer\n",
    "    :return: ndarray, (N:bool,),\n",
    "    \"\"\"\n",
    "    preds = preds + 1e-8\n",
    "\n",
    "    sort_preds = np.sort(preds)\n",
    "    diff = (sort_preds[:, -1] - sort_preds[:, -2]) / (sort_preds[:, -1] - sort_preds[:, 0])\n",
    "\n",
    "    is_border = np.zeros(len(diff), dtype=np.bool)\n",
    "    is_border[diff < threshold] = 1\n",
    "    return is_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 12286.61it/s]\n",
      "/home/xianglin/miniconda3/envs/SV/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "curr_data = curr_data.cpu().numpy()\n",
    "pred = data_provider.get_pred(7, curr_data)\n",
    "preds = np.argmax(pred, axis=1)\n",
    "labels = data_provider.train_labels(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xianglin/miniconda3/envs/SV/lib/python3.7/site-packages/ipykernel_launcher.py:14: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "isB = is_B(pred, 0.2)\n",
    "l = np.logical_and((preds==3),(labels == 5))\n",
    "np.sum(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(isB[l])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa7a9f36e1a1e240450dbe9cc8f6d8df1d5301f36681fb271c44fdd883236b60"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('SV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
