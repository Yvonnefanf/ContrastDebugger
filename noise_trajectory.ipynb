{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xianglin/miniconda3/envs/timevis/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import json\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.SingleVisualizationModel import SingleVisualizationModel\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.eval.evaluator import Evaluator\n",
    "from singleVis.projector import Projector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"symmetric\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/xianglin/data/noisy/{}/embedding.npy\".format(dataset)\n",
    "embeddings = np.load(path)\n",
    "\n",
    "path = \"/home/xianglin/data/noisy/{}/clean_label.json\".format(dataset)\n",
    "with open(path, \"r\") as f:\n",
    "    clean_label = json.load(f)\n",
    "path = \"/home/xianglin/data/noisy/{}/noisy_label.json\".format(dataset)\n",
    "with open(path, \"r\") as f:\n",
    "    noisy_label = json.load(f)\n",
    "\n",
    "clean_label = np.array(clean_label)\n",
    "noisy_label = np.array(noisy_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTENT_PATH = \"/home/xianglin/data/noisy/symmetric\"\n",
    "sys.path.append(CONTENT_PATH)\n",
    "from config import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n"
     ]
    }
   ],
   "source": [
    "GPU_ID = 0\n",
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "PREPROCESS = config[\"VISUALIZATION\"][\"PREPROCESS\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "LAMBDA = VISUALIZATION_PARAMETER[\"LAMBDA\"]\n",
    "S_LAMBDA = VISUALIZATION_PARAMETER[\"S_LAMBDA\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "INIT_NUM = VISUALIZATION_PARAMETER[\"INIT_NUM\"]\n",
    "ALPHA = VISUALIZATION_PARAMETER[\"ALPHA\"]\n",
    "BETA = VISUALIZATION_PARAMETER[\"BETA\"]\n",
    "MAX_HAUSDORFF = VISUALIZATION_PARAMETER[\"MAX_HAUSDORFF\"]\n",
    "HIDDEN_LAYER = VISUALIZATION_PARAMETER[\"HIDDEN_LAYER\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "T_N_EPOCHS = VISUALIZATION_PARAMETER[\"T_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "SEGMENTS = VISUALIZATION_PARAMETER[\"SEGMENTS\"]\n",
    "RESUME_SEG = VISUALIZATION_PARAMETER[\"RESUME_SEG\"]\n",
    "# define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "content_path = CONTENT_PATH\n",
    "sys.path.append(content_path)\n",
    "\n",
    "import Model.model as subject_model\n",
    "# net = resnet18()\n",
    "net = eval(\"subject_model.{}()\".format(NET))\n",
    "classes = (\"airplane\", \"car\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\")\n",
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "if PREPROCESS:\n",
    "    data_provider.initialize(LEN//10, l_bound=L_BOUND)\n",
    "\n",
    "model = SingleVisualizationModel(input_dims=512, output_dims=2, units=256, hidden_layer=HIDDEN_LAYER)\n",
    "projector = Projector(vis_model=model, content_path=CONTENT_PATH, segments=SEGMENTS, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = np.zeros((200, 50000, 512))\n",
    "for i in range(1, 201, 1):\n",
    "    samples[i-1] = data_provider.train_representation(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_2d = np.zeros((200, 50000, 2))\n",
    "for e in range(1, 201, 1):\n",
    "    embeddings_2d[e-1] = projector.batch_project(e, samples[e-1])\n",
    "embeddings_2d = np.transpose(embeddings_2d, [1,0,2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = data_provider.train_representation(200)\n",
    "path = os.path.join(CONTENT_PATH, \"Model\",\"embeddings.npy\")\n",
    "embeddings_2d = np.load(path)\n",
    "embeddings_2d = np.transpose(embeddings_2d, [1,0,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_idxs = np.argwhere(clean_label!=noisy_label).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(CONTENT_PATH, \"Model\",\"embeddings.npy\")\n",
    "np.save(path,embeddings_2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 512), (200, 50000, 2))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.shape, embeddings_2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trajectory_manager import TrajectoryManager, FeedbackTrajectoryManager\n",
    "tm = FeedbackTrajectoryManager(samples, embeddings_2d,30, period=100,metric=\"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tm.clustered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 100\n"
     ]
    }
   ],
   "source": [
    "selected = tm.sample_batch(100)\n",
    "print(len(np.intersect1d(selected, noise_idxs)), len(selected))\n",
    "correct = np.intersect1d(selected, noise_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 100\n",
      "27 100\n",
      "22 100\n",
      "21 100\n",
      "22 100\n",
      "42 100\n",
      "30 100\n",
      "19 100\n",
      "27 100\n",
      "20 100\n"
     ]
    }
   ],
   "source": [
    "# just sampling\n",
    "for _ in range(10):\n",
    "    selected = tm.sample_batch(100)\n",
    "    print(len(np.intersect1d(selected, noise_idxs)), len(selected))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OMP: Info #276: omp_set_nested routine deprecated, please use omp_set_max_active_levels instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 100\n",
      "34 100\n",
      "36 100\n",
      "33 100\n",
      "32 100\n",
      "30 100\n",
      "27 100\n",
      "33 100\n",
      "44 100\n",
      "38 100\n"
     ]
    }
   ],
   "source": [
    "# hybrid\n",
    "for _ in range(10):\n",
    "    tm.update_belief(correct)\n",
    "    selected = tm.sample_batch(100)\n",
    "    print(len(np.intersect1d(selected, noise_idxs)), len(selected))\n",
    "    correct = np.intersect1d(selected, noise_idxs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('timevis': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ee9d2b45af2f0386ad86dea8873e1fdf9843516f676ff1d447c55abb6a82f45d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
