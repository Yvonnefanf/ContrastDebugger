{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:01<00:00, 236.70it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 1863.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict diff sample number: 461 absolute align sample number: 21\n",
      "RBF Kernel CKA, between same subset: 0.9741419572495716\n",
      "RBF Kernel CKA, between diff subset: 0.7450483569371277\n",
      "RBF Kernel CKA, between diff subset: 0.7589473538167805\n",
      "RBF Kernel CKA, between same+diff subset: 0.7563167105946322\n"
     ]
    }
   ],
   "source": [
    "#### \n",
    "\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.data import NormalDataProvider\n",
    "REF_PATH = \"/home/yifan/dataset/resnetwithoutnoise/pairflip/cifar10/0\"\n",
    "\n",
    "CLEAN_PATH = \"/home/yifan/dataset/resnetnoise/pairflip/cifar10/0\"\n",
    "sys.path.append(REF_PATH)\n",
    "\n",
    "\n",
    "from config import config\n",
    "\n",
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "GPU_ID = config[\"GPU\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "PREPROCESS = VISUALIZATION_PARAMETER[\"PREPROCESS\"]\n",
    "LAMBDA = VISUALIZATION_PARAMETER[\"LAMBDA\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "INIT_NUM = VISUALIZATION_PARAMETER[\"INIT_NUM\"]\n",
    "ALPHA = VISUALIZATION_PARAMETER[\"ALPHA\"]\n",
    "BETA = VISUALIZATION_PARAMETER[\"BETA\"]\n",
    "MAX_HAUSDORFF = VISUALIZATION_PARAMETER[\"MAX_HAUSDORFF\"]\n",
    "# HIDDEN_LAYER = VISUALIZATION_PARAMETER[\"HIDDEN_LAYER\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "T_N_EPOCHS = VISUALIZATION_PARAMETER[\"T_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "VIS_MODEL_NAME = 'vis'\n",
    "EVALUATION_NAME = VISUALIZATION_PARAMETER[\"EVALUATION_NAME\"]\n",
    "\n",
    "SEGMENTS = [(EPOCH_START, EPOCH_END)]\n",
    "# define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))\n",
    "\n",
    "\n",
    "ref_provider = NormalDataProvider(REF_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "tar_provider = NormalDataProvider(CLEAN_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "ref_train_data = ref_provider.train_representation(200).squeeze()\n",
    "tar_train_data = tar_provider.train_representation(200).squeeze()\n",
    "ref_prediction = ref_provider.get_pred(200, ref_train_data)\n",
    "tar_prediction = tar_provider.get_pred(200, tar_train_data)\n",
    "ref_prediction_res = ref_prediction.argmax(axis=1)\n",
    "tar_prediction_res = tar_prediction.argmax(axis=1)\n",
    "### get confidence scores result\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "def get_conf(pred):\n",
    "    scores = np.amax(softmax(pred, axis=1), axis=1)\n",
    "    return scores\n",
    "ref_scores = get_conf(ref_prediction)\n",
    "tar_scores =  get_conf(tar_prediction)\n",
    "\n",
    "import math\n",
    "distance_high_indicates = []\n",
    "same_set_indicates = []\n",
    "def EMAE(Y, y, a=1.5):\n",
    "    \"\"\"\n",
    "    param：\n",
    "        Y: 原始序列（假定波动较大）\n",
    "        y: 拟合序列（假定波动较小）\n",
    "        a: 指数的自变量，≥1，该值越大，则两序列间的残差（特别是残差的离群值）对EMAE返回值影响的强化作用越明显；\n",
    "        当a=1时，EMAE化简为MAE。\n",
    "    return：\n",
    "        指数MAE值，该值的大小与两条序列间平均偏差程度成正比，该值越大，平均偏差程度越大；\n",
    "        且两序列间的残差（特别是残差的离群值）对EMAE的影响比MAE大。\n",
    "    \"\"\"\n",
    "\n",
    "    Y, y = np.array(Y), np.array(y)\n",
    "    Y[Y < 0] = 0  # 使指数的底数≥1，则所有指数均为递增函数\n",
    "    y[y < 0] = 0\n",
    "    emae = sum(abs((Y+1)**a - (y+1)**a)) / len(Y)\n",
    "\n",
    "    return emae\n",
    "\n",
    "for i in range(len(ref_prediction)):\n",
    "    mes_val = EMAE(ref_prediction[i], tar_prediction[i])\n",
    "    if mes_val > 30:\n",
    "        distance_high_indicates.append(i)\n",
    "    elif mes_val < 0.3:\n",
    "        same_set_indicates.append(i)\n",
    "#### \n",
    "diff_indicates = []\n",
    "same_indicates = []\n",
    "for i in range(len(ref_prediction)):\n",
    "    # if tar_prediction_res[i] == ref_prediction_res[i] and ref_scores[i] == tar_scores[i] and  (i in same_set_indicates): \n",
    "    if tar_prediction_res[i] == ref_prediction_res[i] and math.fabs(ref_scores[i] - tar_scores[i]) < 0.1 and  (i in same_set_indicates):     \n",
    "        same_indicates.append(i)\n",
    "    else:\n",
    "        diff_indicates.append(i)\n",
    "\n",
    "# need_adjust_indicates = []\n",
    "# for i in range(len(ref_prediction)):\n",
    "#     if tar_prediction_res[i] == ref_prediction_res[i] and ref_scores[i] == tar_scores[i] and  (i in same_set_indicates):     \n",
    "#         same_indicates.append(i)\n",
    "#     else:\n",
    "#         diff_indicates.append(i)\n",
    "pred_diff_list = []\n",
    "for i in range(len(ref_prediction)):\n",
    "    # if tar_prediction_res[i] == ref_prediction_res[i] and ref_scores[i] == tar_scores[i] and  (i in same_set_indicates): \n",
    "    if tar_prediction_res[i] != ref_prediction_res[i] or math.fabs(ref_scores[i] - tar_scores[i]) > 0.3:     \n",
    "        pred_diff_list.append(i)\n",
    "pred_diff_class = []\n",
    "for i in range(len(ref_prediction)):\n",
    "    # if tar_prediction_res[i] == ref_prediction_res[i] and ref_scores[i] == tar_scores[i] and  (i in same_set_indicates): \n",
    "    if tar_prediction_res[i] != ref_prediction_res[i]:     \n",
    "        pred_diff_class.append(i)\n",
    "\n",
    "print('predict diff sample number:',len(pred_diff_list),'absolute align sample number:',len(same_indicates))\n",
    "\n",
    "diff_combine_same = np.concatenate((same_indicates, pred_diff_list), axis=0)\n",
    "# diff_combine_same.sort()\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from CKA_utils.CKA import CKA, CudaCKA\n",
    "np_cka = CKA()\n",
    "print('RBF Kernel CKA, between same subset: {}'.format(np_cka.kernel_CKA(ref_train_data[same_indicates], tar_train_data[same_indicates])))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(np_cka.kernel_CKA(ref_train_data[pred_diff_list], tar_train_data[pred_diff_list])))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(np_cka.kernel_CKA(ref_train_data[pred_diff_class], tar_train_data[pred_diff_class])))\n",
    "print('RBF Kernel CKA, between same+diff subset: {}'.format(np_cka.kernel_CKA(ref_train_data[diff_combine_same], tar_train_data[diff_combine_same])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/ipykernel_launcher.py:29: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/ipykernel_launcher.py:30: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15583565831184387\n",
      "loss tensor(0.8362, grad_fn=<RsubBackward1>)\n",
      "loss tensor(0.8315, grad_fn=<RsubBackward1>)\n",
      "loss tensor(0.8267, grad_fn=<RsubBackward1>)\n",
      "loss tensor(0.8219, grad_fn=<RsubBackward1>)\n",
      "loss tensor(0.8171, grad_fn=<RsubBackward1>)\n",
      "loss tensor(0.8121, grad_fn=<RsubBackward1>)\n",
      "loss tensor(0.8071, grad_fn=<RsubBackward1>)\n",
      "loss tensor(0.8020, grad_fn=<RsubBackward1>)\n",
      "loss tensor(0.7969, grad_fn=<RsubBackward1>)\n",
      "loss tensor(0.7918, grad_fn=<RsubBackward1>)\n",
      "RBF Kernel CKA, between same subset: 0.9741654396057129\n",
      "RBF Kernel CKA, between diff subset: 0.7450482845306396\n",
      "RBF Kernel CKA, between diff subset: 0.7589473724365234\n",
      "RBF Kernel CKA, between same+diff subset: 0.7563166618347168\n",
      "RBF Kernel CKA, between same subset: 0.9741654396057129\n",
      "RBF Kernel CKA, between diff subset: 0.7450482845306396\n",
      "RBF Kernel CKA, between diff subset: 0.7589473724365234\n",
      "RBF Kernel CKA, between same+diff subset: 0.7563166618347168\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "\n",
    "def rbf(X, sigma=None):\n",
    "    # X = torch.tensor(X)\n",
    "    GX = torch.matmul(X, X.T)\n",
    "    KX = torch.diag(GX) - GX + (torch.diag(GX) - GX).T\n",
    "    if sigma is None:\n",
    "        mdist = torch.median(KX[KX != 0])\n",
    "        sigma = torch.sqrt(mdist)\n",
    "    KX *= - 0.5 / (sigma * sigma)\n",
    "    KX = torch.exp(KX)\n",
    "    return KX\n",
    "\n",
    "def kernel_HSIC(X, Y, gamma):\n",
    "    n1 = X.shape[0]\n",
    "    n2 = Y.shape[0]\n",
    "    H1 = torch.eye(n1) - torch.ones(n1, n1) / n1\n",
    "    H2 = torch.eye(n2) - torch.ones(n2, n2) / n2\n",
    "    K1 = torch.matmul(torch.matmul(H1, rbf(X, gamma)), H1)\n",
    "    K2 = torch.matmul(torch.matmul(H2, rbf(Y, gamma)), H2)\n",
    "    hsic = torch.trace(torch.matmul(K1, K2))\n",
    "    return hsic\n",
    "\n",
    "def cka(X, Y, sigma=None):\n",
    "    hsic = kernel_HSIC(X, Y, sigma)\n",
    "    var1 = torch.tensor(kernel_HSIC(X, X, sigma))\n",
    "    var2 = torch.tensor(kernel_HSIC(Y, Y, sigma))\n",
    "    cka = hsic / torch.sqrt(var1 * var2)\n",
    "    return cka.item()\n",
    "\n",
    "\n",
    "    \n",
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(100, 10)\n",
    "\n",
    "cka_value = cka(X, Y)\n",
    "print(cka_value)\n",
    "\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "def objective_value(Y, X, gamma=None):\n",
    " \n",
    "    K_xx = kernel_HSIC(X, X, gamma)\n",
    "    K_yy = kernel_HSIC(Y, Y, gamma)\n",
    "    # K_xy = rbf_kernel(X, Y, 1e-2) \n",
    "    K_xy = kernel_HSIC(X, Y, gamma)   \n",
    "    cka = torch.mean(K_xy) / torch.sqrt(K_xx * K_yy)\n",
    "    return cka\n",
    "\n",
    "def objective(Y, X, gamma=None):\n",
    " \n",
    "    K_xx = kernel_HSIC(X, X, gamma)\n",
    "    K_yy = kernel_HSIC(Y, Y, gamma)\n",
    "    # K_xy = rbf_kernel(X, Y, 1e-2) \n",
    "    K_xy = kernel_HSIC(X, Y, gamma)   \n",
    "    cka_loss = 1 - torch.mean(K_xy) / torch.sqrt(K_xx * K_yy)\n",
    "    return cka_loss\n",
    "\n",
    "Y = torch.randn(100, 10, requires_grad=True)\n",
    "optimizer = Adam([Y], lr=1e-2)\n",
    "\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    loss = objective(X,Y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    print('loss',loss)\n",
    "    optimizer.step()\n",
    "    \n",
    "print('RBF Kernel CKA, between same subset: {}'.format(objective_value(torch.Tensor(ref_train_data[same_indicates]), torch.Tensor(tar_train_data[same_indicates]))))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(objective_value(torch.Tensor(ref_train_data[pred_diff_list]), torch.Tensor(tar_train_data[pred_diff_list]))))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(objective_value(torch.Tensor(ref_train_data[pred_diff_class]), torch.Tensor(tar_train_data[pred_diff_class]))))\n",
    "print('RBF Kernel CKA, between same+diff subset: {}'.format(objective_value(torch.Tensor(ref_train_data[diff_combine_same]), torch.Tensor(tar_train_data[diff_combine_same]))))\n",
    "\n",
    "print('RBF Kernel CKA, between same subset: {}'.format(cka(torch.Tensor(ref_train_data[same_indicates]), torch.Tensor(tar_train_data[same_indicates]))))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(cka(torch.Tensor(ref_train_data[pred_diff_list]), torch.Tensor(tar_train_data[pred_diff_list]))))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(cka(torch.Tensor(ref_train_data[pred_diff_class]), torch.Tensor(tar_train_data[pred_diff_class]))))\n",
    "print('RBF Kernel CKA, between same+diff subset: {}'.format(cka(torch.Tensor(ref_train_data[diff_combine_same]), torch.Tensor(tar_train_data[diff_combine_same]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 1990.55it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 1861.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from alignment.ReferenceGenerator import ReferenceGenerator\n",
    "gen = ReferenceGenerator(ref_provider=ref_provider, tar_provider=tar_provider,REF_EPOCH=200,TAR_EPOCH=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute alignment indicates number: 97 label diff indicates number: 231 confidence diff indicates number: 230\n",
      "Iteration 0: CKA loss = 0.7167\n",
      "Iteration 9: CKA loss = 0.6054\n",
      "Iteration 18: CKA loss = 0.4591\n",
      "Iteration 27: CKA loss = 0.3147\n",
      "Iteration 36: CKA loss = 0.2118\n",
      "Iteration 45: CKA loss = 0.1489\n",
      "Iteration 54: CKA loss = 0.1097\n",
      "Iteration 63: CKA loss = 0.0842\n",
      "Iteration 72: CKA loss = 0.0668\n",
      "Iteration 81: CKA loss = 0.0545\n",
      "Iteration 90: CKA loss = 0.0455\n",
      "Iteration 99: CKA loss = 0.0387\n"
     ]
    }
   ],
   "source": [
    "aaa = gen.generate_representation_by_cka(35, 0.5,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absolute alignment indicates number: 97 label diff indicates number: 231 confidence diff indicates number: 230\n",
      "RBF Kernel CKA, between diff subset: 0.8104318443761\n",
      "RBF Kernel CKA, between diff subset: 0.7589473538167805\n",
      "RBF Kernel CKA, between diff subset: 0.6366090969299499\n"
     ]
    }
   ],
   "source": [
    "absolute_alignment_indicates,predict_label_diff_indicates,predict_confidence_Diff_indicates = gen.subsetClassify(35, 0.5)\n",
    "diff_combine_same = np.concatenate((absolute_alignment_indicates, predict_label_diff_indicates), axis=0)\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(np_cka.kernel_CKA(ref_train_data[diff_combine_same], tar_train_data[diff_combine_same])))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(np_cka.kernel_CKA(ref_train_data[predict_label_diff_indicates], tar_train_data[predict_label_diff_indicates])))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(np_cka.kernel_CKA(np.concatenate((ref_train_data[absolute_alignment_indicates],aaa),axis=0), tar_train_data[diff_combine_same])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0787e-01,  4.5586e-01,  1.2183e+00,  ...,  9.7048e-03,\n",
       "          3.6762e-01,  9.9860e-02],\n",
       "        [ 6.7021e-01,  2.3573e-02,  9.6027e-03,  ...,  9.2427e-05,\n",
       "          8.9656e-01,  8.8440e-04],\n",
       "        [ 0.0000e+00,  1.0089e-02,  1.1115e-02,  ...,  1.4065e+00,\n",
       "          4.0381e-01,  0.0000e+00],\n",
       "        ...,\n",
       "        [-2.8396e-01,  2.0677e+00,  6.0495e-01,  ...,  4.7041e-01,\n",
       "          1.5229e+00, -1.9884e-01],\n",
       "        [ 1.5869e+00,  5.3166e-01,  1.1167e+00,  ...,  5.5588e-01,\n",
       "          1.4619e+00, -1.5788e+00],\n",
       "        [-3.7586e-01,  9.3878e-02, -2.0133e+00,  ...,  5.2337e-01,\n",
       "          1.6253e+00,  1.2470e+00]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0787e-01,  4.5586e-01,  1.2183e+00,  ...,  9.7048e-03,\n",
       "          3.6762e-01,  9.9860e-02],\n",
       "        [ 6.7021e-01,  2.3573e-02,  9.6027e-03,  ...,  9.2427e-05,\n",
       "          8.9656e-01,  8.8440e-04],\n",
       "        [ 0.0000e+00,  1.0089e-02,  1.1115e-02,  ...,  1.4065e+00,\n",
       "          4.0381e-01,  0.0000e+00],\n",
       "        ...,\n",
       "        [-4.6379e-01, -3.9944e-01,  3.2981e-01,  ...,  4.5481e-01,\n",
       "         -1.9631e+00,  1.5185e+00],\n",
       "        [-1.1161e+00, -1.7232e+00, -9.9265e-01,  ..., -4.2883e-02,\n",
       "         -1.0176e+00,  1.1383e+00],\n",
       "        [-2.5949e-01, -8.4106e-02,  4.6334e-01,  ..., -4.1069e-01,\n",
       "          2.6556e-01, -9.1836e-01]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/ipykernel_launcher.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "new(): data must be a sequence (got float)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1940425/2848363164.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1940425/2848363164.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(Y, X, gamma)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mK_xx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbf_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mK_yy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrbf_kernel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mK_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel_HSIC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mcka\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_xy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_xx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_yy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mcka\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: new(): data must be a sequence (got float)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "# def rbf_kernel(X, Y, gamma):\n",
    "#     X_norms = (X ** 2).sum(dim=1, keepdim=True)\n",
    "#     Y_norms = (Y ** 2).sum(dim=1, keepdim=True)\n",
    "#     K = torch.exp(-gamma * (X_norms + Y_norms.T - 2 * torch.mm(X, Y.T)))\n",
    "#     return K\n",
    "\n",
    "def centering(K):\n",
    "    n = K.shape[0]\n",
    "    unit = torch.ones([n, n])\n",
    "    I = torch.eye(n)\n",
    "    H = I - unit / n\n",
    "    K = torch.tensor(K)\n",
    "    return torch.matmul(torch.matmul(H, K), H)\n",
    "\n",
    "# def rbf(X, sigma=None):\n",
    "#         GX = np.dot(X, X.T)\n",
    "#         KX = np.diag(GX) - GX + (np.diag(GX) - GX).T\n",
    "#         if sigma is None:\n",
    "#             mdist = np.median(KX[KX != 0])\n",
    "#             sigma = math.sqrt(mdist)\n",
    "#         KX *= - 0.5 / (sigma * sigma)\n",
    "#         KX = np.exp(KX)\n",
    "#         return KX\n",
    "\n",
    "def rbf(X, sigma=None):\n",
    "    # X = torch.tensor(X)\n",
    "    GX = torch.matmul(X, X.T)\n",
    "    KX = torch.diag(GX) - GX + (torch.diag(GX) - GX).T\n",
    "    if sigma is None:\n",
    "        mdist = torch.median(KX[KX != 0])\n",
    "        sigma = torch.sqrt(mdist)\n",
    "    KX *= - 0.5 / (sigma * sigma)\n",
    "    KX = torch.exp(KX)\n",
    "    return KX\n",
    "\n",
    "\n",
    "def kernel_HSIC(X, Y, sigma):\n",
    "    K_X = centering(rbf(X, sigma))\n",
    "    K_Y = centering(rbf(Y, sigma))\n",
    "    hsic = torch.sum(K_X * K_Y)\n",
    "    return hsic.item()\n",
    "\n",
    "def rbf_kernel(X, sigma=None):\n",
    "    # X = torch.tensor(X)\n",
    "    GX = torch.matmul(X, X.T)\n",
    "    KX = torch.diag(GX) - GX + (torch.diag(GX) - GX).T\n",
    "    if sigma is None:\n",
    "        mdist = torch.median(KX[KX != 0])\n",
    "        sigma = torch.sqrt(mdist)\n",
    "    KX *= - 0.5 / (sigma * sigma)\n",
    "    KX = torch.exp(KX)\n",
    "    return KX\n",
    "\n",
    "\n",
    "def cka(X, Y, sigma=None):\n",
    "    K_X = centering(rbf(X, sigma))\n",
    "    K_Y = centering(rbf(Y, sigma))\n",
    "    hsic = torch.sum(K_X * K_Y)\n",
    "    return hsic.item()\n",
    "    \n",
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(100, 10)\n",
    "\n",
    "cka_value = cka(X, Y)\n",
    "\n",
    "def objective(Y, X=X, gamma=None):\n",
    "    K_xx = rbf_kernel(X, gamma)\n",
    "    K_yy = rbf_kernel(Y, gamma)\n",
    "    K_xy = kernel_HSIC(X, Y, gamma)\n",
    "    cka = torch.mean(K_xy) / torch.sqrt(torch.mean(K_xx) * torch.mean(K_yy))\n",
    "    return -cka\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "Y = torch.randn(100, 10, requires_grad=True)\n",
    "optimizer = Adam([Y], lr=1e-2)\n",
    "\n",
    "for i in range(10):\n",
    "    loss = objective(Y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "Y = Y.detach().numpy()\n",
    "\n",
    "print('RBF Kernel CKA, between same subset: {}'.format(cka(torch.Tensor(ref_train_data[same_indicates]), torch.Tensor(tar_train_data[same_indicates]))))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(cka(torch.Tensor(ref_train_data[pred_diff_list]), torch.Tensor(tar_train_data[pred_diff_list]))))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(cka(torch.Tensor(ref_train_data[pred_diff_class]), torch.Tensor(tar_train_data[pred_diff_class]))))\n",
    "print('RBF Kernel CKA, between same+diff subset: {}'.format(cka(torch.Tensor(ref_train_data[diff_combine_same]), torch.Tensor(tar_train_data[diff_combine_same]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.9984, grad_fn=<NegBackward0>)\n",
      "tensor(-0.9985, grad_fn=<NegBackward0>)\n",
      "tensor(-0.9987, grad_fn=<NegBackward0>)\n",
      "tensor(-0.9988, grad_fn=<NegBackward0>)\n",
      "tensor(-0.9989, grad_fn=<NegBackward0>)\n",
      "tensor(-0.9990, grad_fn=<NegBackward0>)\n",
      "tensor(-0.9991, grad_fn=<NegBackward0>)\n",
      "tensor(-0.9992, grad_fn=<NegBackward0>)\n",
      "tensor(-0.9993, grad_fn=<NegBackward0>)\n",
      "tensor(-0.9994, grad_fn=<NegBackward0>)\n",
      "RBF Kernel CKA, between same subset: 0.7649381160736084\n",
      "RBF Kernel CKA, between diff subset: 0.882797122001648\n",
      "RBF Kernel CKA, between diff subset: 0.8677344918251038\n",
      "RBF Kernel CKA, between same+diff subset: 0.8875225782394409\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def rbf_kernel(X, Y, gamma):\n",
    "    X_norms = (X ** 2).sum(dim=1, keepdim=True)\n",
    "    Y_norms = (Y ** 2).sum(dim=1, keepdim=True)\n",
    "    K = torch.exp(-gamma * (X_norms + Y_norms.T - 2 * torch.mm(X, Y.T)))\n",
    "    return K\n",
    "\n",
    "\n",
    "def cka(X, Y, gamma=1e-2):\n",
    "    K_xx = rbf_kernel(X, X, gamma)\n",
    "    K_yy = rbf_kernel(Y, Y, gamma)\n",
    "    K_xy = rbf_kernel(X, Y, gamma)\n",
    "    cka = torch.mean(K_xy) / torch.sqrt(torch.mean(K_xx) * torch.mean(K_yy))\n",
    "    return cka.item()\n",
    "    \n",
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(100, 10)\n",
    "\n",
    "cka_value = cka(X, Y)\n",
    "\n",
    "def objective(Y, X=X, gamma=1e-2):\n",
    "    K_xx = rbf_kernel(X, X, gamma)\n",
    "    K_yy = rbf_kernel(Y, Y, gamma)\n",
    "    K_xy = rbf_kernel(X, Y, gamma)\n",
    "    cka = torch.mean(K_xy) / torch.sqrt(torch.mean(K_xx) * torch.mean(K_yy))\n",
    "    return -cka\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "Y = torch.randn(100, 10, requires_grad=True)\n",
    "optimizer = Adam([Y], lr=1e-2)\n",
    "\n",
    "for i in range(10):\n",
    "    loss = objective(Y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "Y = Y.detach().numpy()\n",
    "\n",
    "print('RBF Kernel CKA, between same subset: {}'.format(cka(torch.Tensor(ref_train_data[same_indicates]), torch.Tensor(tar_train_data[same_indicates]))))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(cka(torch.Tensor(ref_train_data[pred_diff_list]), torch.Tensor(tar_train_data[pred_diff_list]))))\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(cka(torch.Tensor(ref_train_data[pred_diff_class]), torch.Tensor(tar_train_data[pred_diff_class]))))\n",
    "print('RBF Kernel CKA, between same+diff subset: {}'.format(cka(torch.Tensor(ref_train_data[diff_combine_same]), torch.Tensor(tar_train_data[diff_combine_same]))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = cka(ref_train_data[diff_combine_same], tar_train_data[diff_combine_same],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step2: Computing the loss \n",
    "def compute_loss(X, Y, R):\n",
    "    '''\n",
    "    Inputs: \n",
    "       X: a matrix of dimension (m,n) where the columns are the English embeddings.\n",
    "       Y: a matrix of dimension (m,n) where the columns correspong to the French embeddings.\n",
    "       R: a matrix of dimension (n,n) - transformation matrix from English to French vector space embeddings.\n",
    "    Outputs:\n",
    "       L: a matrix of dimension (m,n) - the value of the loss function for given X, Y and R.\n",
    "    '''\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "    # m is the number of rows in X\n",
    "    m = len(X)\n",
    "\n",
    "    # diff is XR - Y\n",
    "    diff = np.dot(X, R) - Y\n",
    "\n",
    "    # diff_squared is the element-wise square of the difference\n",
    "    diff_squared = diff**2\n",
    "\n",
    "    # sum_diff_squared is the sum of the squared elements\n",
    "    sum_diff_squared = diff_squared.sum()\n",
    "\n",
    "    # loss is the sum_diff_squared divided by the number of examples (m)\n",
    "    loss = sum_diff_squared/m\n",
    "    ### END CODE HERE ###\n",
    "    return loss\n",
    "def compute_gradient(X, Y, R):\n",
    "    '''\n",
    "        the gradient of the loss with respect to the matrix encodes how much a tiny change \n",
    "    in some coordinate of that matrix affect the change of loss function.\n",
    "        Gradient descent uses that information to iteratively change matrix R until we reach \n",
    "    a point where the loss is minimized.\n",
    "    Inputs: \n",
    "        X: a matrix of dimension (m,n) where the colums are the contrast representation \n",
    "        Y: a matrix of dimension (m,n) where the colums are the reference representation\n",
    "        R: a matrix of dimension (n,n) - transformation matrix from Y2d to X2d\n",
    "    Outputs:\n",
    "       g: a matrix of dimension (n,n) - gradient of the loss function L for given X, Y and R.\n",
    "    '''\n",
    "    # m is the number of rows in X\n",
    "    m = len(X)\n",
    "\n",
    "    rows, columns = X.shape\n",
    "\n",
    "    gradient = (np.dot(X.T, np.dot(X, R) - Y) * 2)/rows\n",
    "    assert gradient.shape == (columns, columns)\n",
    "    ### END CODE HERE ###\n",
    "    return gradient\n",
    "\n",
    "\n",
    "# Most of the time we iterate for a fixed number of training steps rather than iterating until the loss falls below a threshold.\n",
    "\n",
    "# 1.Calculate gradient g of the loss with respect to the matrix R. \n",
    "# 2. Update R (Rnew = Rold - αg) . α is the learning rate which is a scalar.\n",
    "\n",
    "# alignment_embeddings\n",
    "def align_embeddings(X: np.ndarray, Y: np.ndarray,\n",
    "                      train_steps:int,\n",
    "                      learning_rate: float=0.0003,\n",
    "                      seed: int=129) -> np.ndarray:\n",
    "    '''\n",
    "    Finding the optimal R with gradient descent algorithm\n",
    "    Inputs:\n",
    "        X: a matrix of dimension (m,n) where the colums are the contrast representation \n",
    "        Y: a matrix of dimension (m,n) where the colums are the reference representation\n",
    "        learning_rate: positive float - describes how big steps will  gradient descent algorithm do.\n",
    "    Outputs:\n",
    "        R: a matrix of dimension (n,n) - the projection matrix that minimizes the F norm ||projector(X R) - projector ( Y )||^2\n",
    "    '''\n",
    "    # the number of columns in X is the number of dimensions for a word vector (e.g. 300)\n",
    "    # R is a square matrix with length equal to the number of dimensions in th  word embedding\n",
    "    R = np.random.rand(X.shape[1], X.shape[1])\n",
    "    # R = Variable(torch.ones(X.shape[1],X.shape[1]),requires_grad=True)\n",
    "\n",
    "   \n",
    "\n",
    "        \n",
    "    # train_steps = 100000\n",
    "    for i in range(train_steps):\n",
    "        if i%1000 == 0:\n",
    "            loss = compute_loss(X,Y,R)\n",
    "            print(f\"iteration {i}, loss {loss}\") \n",
    "\n",
    "\n",
    "\n",
    "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "        # use the function that you defined to compute the gradient\n",
    "        gradient = compute_gradient(X, Y, R)\n",
    "       \n",
    "        \n",
    "         # update R by subtracting the learning rate times gradient\n",
    "        R -= learning_rate * gradient\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    return R\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pred_diff_class)\n",
    "ref_train_data = ref_provider.train_representation(200).squeeze()\n",
    "ref_res_idx = list(zip(range(len(ref_prediction_res)),ref_prediction_res))\n",
    "ref_scores_idx = list(zip(range(len(ref_scores)),ref_scores))\n",
    "\n",
    "for i in range(len(pred_diff_class)):\n",
    "    index = pred_diff_class[i]\n",
    "    ###### find same prediction result in reference\n",
    "    pred_res_in_target = tar_prediction_res[index]\n",
    "    score = tar_scores[index]\n",
    "    res_idx = list(filter(lambda x:x[1]==pred_res_in_target,ref_res_idx))\n",
    "\n",
    "    res_idx = list(zip(*res_idx))[0]\n",
    "    if len(res_idx):\n",
    "        score_idx = list(filter(lambda x:np.logical_and(x[0] in res_idx,math.fabs(x[1] - score) < 0.1),ref_scores_idx))\n",
    "        \n",
    "        if len(score_idx):\n",
    "            score_idx = list(zip(*score_idx))[0]\n",
    "            if i%10 == 0:\n",
    "                print('111',index, score_idx[0])\n",
    "            ref_train_data[index] = ref_train_data[score_idx[0]]\n",
    "\n",
    "\n",
    "    # print('res',pred_res_in_target, 'res',len(score_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ref_train_data[same_indicates]\n",
    "Y = tar_train_data[same_indicates]\n",
    "S_for_same = align_embeddings(X, Y, 35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "show_list = [pred_diff_class[0],pred_diff_class[1],pred_diff_class[7],pred_diff_class[8],pred_diff_class[14],pred_diff_class[16],\n",
    "             pred_diff_class[18],\n",
    "             pred_diff_class[20],pred_diff_class[25],pred_diff_class[29],pred_diff_class[30],pred_diff_class[32],pred_diff_class[33],\n",
    "             pred_diff_class[42],pred_diff_class[43],pred_diff_class[44],pred_diff_class[45],\n",
    "             ]\n",
    "I = np.eye(512)\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "# from representationTrans.visualizer import visualizer\n",
    "vis = visualizer(tar_provider , S_for_same,I, ref_train_data, projector, 200,[show_list],'tab10')\n",
    "save_dir = os.path.join('/home/yifan/projects' , \"imgcontrast\")\n",
    "# os.makedirs(save_dir)\n",
    "\n",
    "vis.savefig(200, path=os.path.join(save_dir, \"origin_contrast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "show_list = [pred_diff_class[0],pred_diff_class[1],pred_diff_class[7],pred_diff_class[8],pred_diff_class[14],pred_diff_class[16],\n",
    "             pred_diff_class[18],\n",
    "             pred_diff_class[20],pred_diff_class[25],pred_diff_class[29],pred_diff_class[30],pred_diff_class[32],pred_diff_class[33],\n",
    "             pred_diff_class[42],pred_diff_class[43],pred_diff_class[44],pred_diff_class[45],\n",
    "             ]\n",
    "I = np.eye(512)\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "# from representationTrans.visualizer import visualizer\n",
    "vis = visualizer(ref_provider, I,I, np.dot(ref_provider.train_representation(200),I), projector, 200,[show_list],'tab10')\n",
    "save_dir = os.path.join('/home/yifan/projects' , \"imgcontrast\")\n",
    "# os.makedirs(save_dir)\n",
    "\n",
    "vis.savefig(200, path=os.path.join(save_dir, \"origin_contrast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use prediction differenct subset train S_for_diff, use S_for_diff generate diff predict samples\n",
    "X = ref_train_data[same_indicates]\n",
    "Y = tar_train_data[same_indicates]\n",
    "R_for_same = align_embeddings(Y, X, 35000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = ref_train_data[diff_combine_same]\n",
    "# Y = tar_train_data[diff_combine_same]\n",
    "# S = align_embeddings(X, Y, 25000)\n",
    "# X = ref_train_data[diff_combine_same]\n",
    "# Y = tar_train_data[diff_combine_same]\n",
    "# R = align_embeddings(Y, X, 25000)\n",
    "# adjusted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "I = np.eye(512)\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "# from representationTrans.visualizer import visualizer\n",
    "vis = visualizer(tar_provider, S_for_same,I, np.dot(tar_provider.train_representation(200),R_for_same), projector, 200,[pred_diff_list],'tab10')\n",
    "save_dir = os.path.join('/home/yifan/projects' , \"imgcontrast\")\n",
    "# os.makedirs(save_dir)\n",
    "\n",
    "vis.savefig(200, path=os.path.join(save_dir, \"origin_contrast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_combine_same = np.concatenate((pred_diff_list, same_indicates), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concatenate(ref_train_data[same_indicates], np.array([ref_train_data[index]])).shape\n",
    "\n",
    "\n",
    "# samelist.append(ref_train_data[0])\n",
    "# la = np.append(samelist, ref_train_data[0], axis=None) \n",
    "# la.shape   \n",
    "# print(index,'RBF Kernel CKA, between diff subset: {}'.format(np_cka.kernel_CKA(ref_train_data[diff_combine_same], tar_train_data[diff_combine_same]))) \n",
    "stand = np_cka.kernel_CKA(ref_train_data[diff_combine_same], tar_train_data[diff_combine_same])                \n",
    "for i in range(len(res_idx)):\n",
    "    index = res_idx[i]\n",
    "    samelist1 = ref_train_data[diff_combine_same]\n",
    "    samelist1[0] = ref_train_data[index]\n",
    "\n",
    "    if(stand - np_cka.kernel_CKA(samelist1, tar_train_data[diff_combine_same]) < 0.001):\n",
    "        print(index,'RBF Kernel CKA, between diff subset: {}'.format(np_cka.kernel_CKA(samelist1, tar_train_data[diff_combine_same])))\n",
    "\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sta_CKA(res_idx, need_adjust_index,ref_representations, tar_representations, threthold):\n",
    "    \"\"\"\n",
    "        res_idx: search subset\n",
    "        need_adjust_index: index of the need adjusted sample\n",
    "        ref_representations: reference representation sub set\n",
    "        tar_representations: target representation sub set\n",
    "        threthold: current CKA\n",
    "    \"\"\"\n",
    "    stand_val = np_cka.kernel_CKA(ref_representations, tar_representations)           \n",
    "    idx = []\n",
    "    for i in range(len(res_idx)):\n",
    "        index = res_idx[i]\n",
    "        ref_representations[need_adjust_index] = ref_train_data[index]\n",
    "\n",
    "        if (stand_val - np_cka.kernel_CKA(ref_representations, tar_representations) < threthold):\n",
    "            idx.append(index)\n",
    "    return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "I = np.eye(512)\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "# from representationTrans.visualizer import visualizer\n",
    "vis = visualizer(tar_provider, S_for_same,I, np.dot(tar_provider.train_representation(200),R_for_same), projector, 200,[pred_diff_list],'tab10')\n",
    "save_dir = os.path.join('/home/yifan/projects' , \"imgcontrast\")\n",
    "# os.makedirs(save_dir)\n",
    "\n",
    "vis.savefig(200, path=os.path.join(save_dir, \"origin_contrast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "I = np.eye(512)\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "# from representationTrans.visualizer import visualizer\n",
    "vis = visualizer(tar_provider, S_for_same,I, np.dot(tar_provider.train_representation(200),R_for_same), projector, 200,[pred_diff_list],'tab10')\n",
    "save_dir = os.path.join('/home/yifan/projects' , \"imgcontrast\")\n",
    "# os.makedirs(save_dir)\n",
    "\n",
    "vis.savefig(200, path=os.path.join(save_dir, \"origin_contrast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=CLEAN_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "I = np.eye(512)\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "# from representationTrans.visualizer import visualizer\n",
    "vis = visualizer(tar_provider, I,I, np.dot(tar_provider.train_representation(200),I), projector, 200,[pred_diff_list],'tab10')\n",
    "save_dir = os.path.join('/home/yifan/projects' , \"imgcontrast\")\n",
    "# os.makedirs(save_dir)\n",
    "\n",
    "vis.savefig(200, path=os.path.join(save_dir, \"origin_contrast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "I = np.eye(512)\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "# from representationTrans.visualizer import visualizer\n",
    "vis = visualizer(ref_provider, I,I, np.dot(ref_provider.train_representation(200),I), projector, 200,[pred_diff_list],'tab10')\n",
    "save_dir = os.path.join('/home/yifan/projects' , \"imgcontrast\")\n",
    "# os.makedirs(save_dir)\n",
    "\n",
    "vis.savefig(200, path=os.path.join(save_dir, \"origin_contrast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.projector import TimeVisProjector\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "I = np.eye(512)\n",
    "from representationTrans.trans_visualizer_border import visualizer\n",
    "# from representationTrans.visualizer import visualizer\n",
    "vis = visualizer(ref_provider, I,I, np.dot(ref_provider.train_representation(200),I), projector, 200,[pred_diff_class],'tab10')\n",
    "save_dir = os.path.join('/home/yifan/projects' , \"imgcontrast\")\n",
    "# os.makedirs(save_dir)\n",
    "\n",
    "vis.savefig(200, path=os.path.join(save_dir, \"origin_contrast\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.dot(ref_train_data[pred_diff_list],S_for_diff)\n",
    "Y = tar_train_data[pred_diff_list]\n",
    "print('RBF Kernel CKA, between np.dot(ref_train_data[pred_diff_list],S_for_diff) and tar_train_data[pred_diff_list]: {}'.format(np_cka.kernel_CKA(X, Y)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edebc873ae2d93bf61542579b755774a0fcf6e84a6839a73f5ee99d2371b4768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
