{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#### \n",
    "\n",
    "import torch\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.data import NormalDataProvider\n",
    "REF_PATH = \"/home/yifan/dataset/clean/pairflip/cifar10/0\"\n",
    "\n",
    "CLEAN_PATH = \"/home/yifan/dataset/noisy/pairflip/cifar10/noisy2500\"\n",
    "sys.path.append(REF_PATH)\n",
    "\n",
    "\n",
    "from config import config\n",
    "\n",
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "GPU_ID = config[\"GPU\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "PREPROCESS = VISUALIZATION_PARAMETER[\"PREPROCESS\"]\n",
    "LAMBDA = VISUALIZATION_PARAMETER[\"LAMBDA\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "INIT_NUM = VISUALIZATION_PARAMETER[\"INIT_NUM\"]\n",
    "ALPHA = VISUALIZATION_PARAMETER[\"ALPHA\"]\n",
    "BETA = VISUALIZATION_PARAMETER[\"BETA\"]\n",
    "MAX_HAUSDORFF = VISUALIZATION_PARAMETER[\"MAX_HAUSDORFF\"]\n",
    "# HIDDEN_LAYER = VISUALIZATION_PARAMETER[\"HIDDEN_LAYER\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "T_N_EPOCHS = VISUALIZATION_PARAMETER[\"T_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "VIS_MODEL_NAME = 'vis'\n",
    "EVALUATION_NAME = VISUALIZATION_PARAMETER[\"EVALUATION_NAME\"]\n",
    "\n",
    "SEGMENTS = [(EPOCH_START, EPOCH_END)]\n",
    "# define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n",
      "Finish initialization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:00<00:00, 601.93it/s]\n",
      "100%|██████████| 250/250 [00:00<00:00, 9612.11it/s]\n"
     ]
    }
   ],
   "source": [
    "REF_EPOCH = 200\n",
    "TAR_EPOCH = 200\n",
    "ref_provider = NormalDataProvider(REF_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "tar_provider = NormalDataProvider(CLEAN_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "ref_train_data = ref_provider.train_representation(REF_EPOCH).squeeze()\n",
    "tar_train_data = tar_provider.train_representation(TAR_EPOCH).squeeze()\n",
    "ref_prediction = ref_provider.get_pred(REF_EPOCH, ref_train_data)\n",
    "tar_prediction = tar_provider.get_pred(TAR_EPOCH, tar_train_data)\n",
    "ref_prediction_res = ref_prediction.argmax(axis=1)\n",
    "tar_prediction_res = tar_prediction.argmax(axis=1)\n",
    "### get confidence scores result\n",
    "from scipy.special import softmax\n",
    "import numpy as np\n",
    "def get_conf(pred):\n",
    "    scores = np.amax(softmax(pred, axis=1), axis=1)\n",
    "    return scores\n",
    "ref_scores = get_conf(ref_prediction)\n",
    "tar_scores =  get_conf(tar_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_high_indicates = []\n",
    "same_set_indicates = []\n",
    "def EMAE(Y, y, a=1.5):\n",
    "    \"\"\"\n",
    "    param：\n",
    "        Y: 原始序列（假定波动较大）\n",
    "        y: 拟合序列（假定波动较小）\n",
    "        a: 指数的自变量，≥1，该值越大，则两序列间的残差（特别是残差的离群值）对EMAE返回值影响的强化作用越明显；\n",
    "        当a=1时，EMAE化简为MAE。\n",
    "    return：\n",
    "        指数MAE值，该值的大小与两条序列间平均偏差程度成正比，该值越大，平均偏差程度越大；\n",
    "        且两序列间的残差（特别是残差的离群值）对EMAE的影响比MAE大。\n",
    "    \"\"\"\n",
    "\n",
    "    Y, y = np.array(Y), np.array(y)\n",
    "    Y[Y < 0] = 0  # 使指数的底数≥1，则所有指数均为递增函数\n",
    "    y[y < 0] = 0\n",
    "    emae = sum(abs((Y+1)**a - (y+1)**a)) / len(Y)\n",
    "\n",
    "    return emae\n",
    "\n",
    "for i in range(len(ref_prediction)):\n",
    "    mes_val = EMAE(ref_prediction[i], tar_prediction[i])\n",
    "    if mes_val > 10:\n",
    "        distance_high_indicates.append(i)\n",
    "    elif mes_val < 1:\n",
    "        same_set_indicates.append(i)\n",
    "#### \n",
    "diff_indicates = []\n",
    "same_indicates = []\n",
    "for i in range(len(ref_prediction)):\n",
    "    if tar_prediction_res[i] == ref_prediction_res[i] and ref_scores[i] == tar_scores[i] and  (i in same_set_indicates):     \n",
    "        same_indicates.append(i)\n",
    "    else:\n",
    "        diff_indicates.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7027"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(distance_high_indicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample number: 162 CKA 0.9999999999999993\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import CCA\n",
    "# 建立模型\n",
    "X = ref_train_data[same_indicates]\n",
    "Y = tar_train_data[same_indicates]\n",
    "cca = CCA(n_components=1)\n",
    "# 训练数据\n",
    "cca.fit(X, Y)\n",
    "# print(X)\n",
    "X_train_r, Y_train_r = cca.transform(X, Y)\n",
    "# print(X_train_r)\n",
    "print('sample number:',len(same_indicates), 'CKA',np.corrcoef(X_train_r[:, 0], Y_train_r[:, 0])[0, 1]) #输出相关系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import CCA\n",
    "# 建立模型\n",
    "X = ref_prediction[same_indicates]\n",
    "Y = tar_prediction[same_indicates]\n",
    "cca = CCA(n_components=1)\n",
    "# 训练数据\n",
    "cca.fit(X, Y)\n",
    "# print(X)\n",
    "X_train_r, Y_train_r = cca.transform(X, Y)\n",
    "# print(X_train_r)\n",
    "print('sample number:',len(distance_high_indicates), 'CKA',np.corrcoef(X_train_r[:, 0], Y_train_r[:, 0])[0, 1]) #输出相关系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample number: 7027 CKA 0.9553629770329473\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cross_decomposition import CCA\n",
    "# 建立模型\n",
    "X = ref_prediction\n",
    "Y = tar_prediction\n",
    "cca = CCA(n_components=1)\n",
    "# 训练数据\n",
    "cca.fit(X, Y)\n",
    "# print(X)\n",
    "X_train_r, Y_train_r = cca.transform(X, Y)\n",
    "# print(X_train_r)\n",
    "print('sample number:',len(distance_high_indicates), 'CKA',np.corrcoef(X_train_r[:, 0], Y_train_r[:, 0])[0, 1]) #输出相关系数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edebc873ae2d93bf61542579b755774a0fcf6e84a6839a73f5ee99d2371b4768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
