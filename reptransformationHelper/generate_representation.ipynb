{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Normalized CCA value = 16.7968\n",
      "Iteration 100: Normalized CCA value = 24.9161\n",
      "Iteration 200: Normalized CCA value = 29.2382\n",
      "Iteration 300: Normalized CCA value = 31.9819\n",
      "Iteration 400: Normalized CCA value = 34.1554\n",
      "Iteration 500: Normalized CCA value = 35.8794\n",
      "Iteration 600: Normalized CCA value = 37.1309\n",
      "Iteration 700: Normalized CCA value = 38.3227\n",
      "Iteration 800: Normalized CCA value = 39.2704\n",
      "Iteration 900: Normalized CCA value = 39.3329\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the CCA loss function\n",
    "def cca_loss(x, y):\n",
    "    # Normalize the input data\n",
    "    x_normalized = torch.nn.functional.normalize(x, dim=0)\n",
    "    y_normalized = torch.nn.functional.normalize(y, dim=0)\n",
    "\n",
    "    # Compute the covariance matrix of the normalized input data\n",
    "    cov = torch.matmul(x_normalized.T, y_normalized)\n",
    "\n",
    "    # Compute the singular value decomposition of the covariance matrix\n",
    "    u, s, v = torch.svd(cov)\n",
    "\n",
    "    # Compute the canonical correlation coefficients\n",
    "    cca_coef = s[:min(x.shape[1], y.shape[1])]\n",
    "\n",
    "    # Normalize the CCA coefficients\n",
    "    cca_coef_norm = cca_coef / torch.max(cca_coef)\n",
    "\n",
    "    # Compute the loss function\n",
    "    loss = 1 - cca_coef_norm.sum()\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Define the model and optimizer\n",
    "x = torch.randn(100, 50)  # Fixed input X\n",
    "y = torch.randn(100, 50, requires_grad=True)  # Model parameters Y\n",
    "\n",
    "optimizer = optim.SGD([y], lr=0.1)\n",
    "\n",
    "# Train the model to maximize the normalized CCA value\n",
    "for i in range(1000):\n",
    "    loss = cca_loss(x, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the normalized CCA value every 100 iterations\n",
    "    if i % 100 == 0:\n",
    "        cca_coef = torch.svd(torch.matmul(x.T, y))[1][:min(x.shape[1], y.shape[1])]\n",
    "        cca_coef_norm = cca_coef / torch.max(cca_coef)\n",
    "        print(f\"Iteration {i}: Normalized CCA value = {cca_coef_norm.sum().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: CCA value = 8.0445\n",
      "Iteration 100: CCA value = 15.9398\n",
      "Iteration 200: CCA value = 16.8100\n",
      "Iteration 300: CCA value = 17.0379\n",
      "Iteration 400: CCA value = 17.4920\n",
      "Iteration 500: CCA value = 17.1443\n",
      "Iteration 600: CCA value = 16.9245\n",
      "Iteration 700: CCA value = 17.2129\n",
      "Iteration 800: CCA value = 17.3528\n",
      "Iteration 900: CCA value = 16.8542\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the deep neural network model\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Define the CCA loss function\n",
    "def cca_loss(x, y):\n",
    "    # Normalize the input data\n",
    "    x_normalized = torch.nn.functional.normalize(x, dim=0)\n",
    "    y_normalized = torch.nn.functional.normalize(y, dim=0)\n",
    "\n",
    "    # Compute the covariance matrix of the normalized input data\n",
    "    cov = torch.matmul(x_normalized.T, y_normalized)\n",
    "\n",
    "    # Compute the singular value decomposition of the covariance matrix\n",
    "    u, s, v = torch.svd(cov)\n",
    "\n",
    "    # Compute the canonical correlation coefficients\n",
    "    cca_coef = s[:min(x.shape[1], y.shape[1])]\n",
    "\n",
    "    # Normalize the CCA coefficients\n",
    "    cca_coef_norm = cca_coef / torch.max(cca_coef)\n",
    "\n",
    "    # Compute the loss function\n",
    "    loss = 1 - cca_coef_norm.sum()\n",
    "\n",
    "    return loss\n",
    "\n",
    "# Define the data and model parameters\n",
    "x = torch.randn(100, 50)\n",
    "y = torch.randn(100, 50, requires_grad=True)\n",
    "\n",
    "model = Model(input_size=50, hidden_size=100, output_size=50)\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "# Train the model to maximize the CCA value\n",
    "for i in range(1000):\n",
    "    y_pred = model(x)\n",
    "    loss = cca_loss(y_pred, y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # Print the CCA value every 100 iterations\n",
    "    if i % 100 == 0:\n",
    "        cca_coef = torch.svd(torch.matmul(x.T, y_pred))[1][:min(x.shape[1], y_pred.shape[1])]\n",
    "        cca_coef_norm = cca_coef / torch.max(cca_coef)\n",
    "        print(f\"Iteration {i}: CCA value = {cca_coef_norm.sum().item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1845320/1016299410.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1845320/1016299410.py\u001b[0m in \u001b[0;36mobjective\u001b[0;34m(Y, X, gamma)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mK_xx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_HSIC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m     \u001b[0mK_yy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_HSIC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m     \u001b[0mK_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_HSIC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mcka\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_xy\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_xx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK_yy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1845320/1016299410.py\u001b[0m in \u001b[0;36mkernel_HSIC\u001b[0;34m(X, Y, sigma)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mkernel_HSIC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcentering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1845320/1016299410.py\u001b[0m in \u001b[0;36mrbf\u001b[0;34m(X, sigma)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrbf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mGX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mKX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mGX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mGX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msigma\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__array__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Can't call numpy() on Tensor that requires grad. Use tensor.detach().numpy() instead."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "import math\n",
    "def rbf(X, sigma=None):\n",
    "    GX = np.dot(X, X.T)\n",
    "    KX = np.diag(GX) - GX + (np.diag(GX) - GX).T\n",
    "    if sigma is None:\n",
    "        mdist = np.median(KX[KX != 0])\n",
    "        sigma = math.sqrt(mdist)\n",
    "    KX *= - 0.5 / (sigma * sigma)\n",
    "    KX = np.exp(KX)\n",
    "    return KX\n",
    "\n",
    "def centering(K):\n",
    "    n = K.shape[0]\n",
    "    unit = np.ones([n, n])\n",
    "    I = np.eye(n)\n",
    "    H = I - unit / n\n",
    "    return np.dot(np.dot(H, K), H) \n",
    "\n",
    "def kernel_HSIC(X, Y, sigma):\n",
    "    return np.sum(centering(rbf(X, sigma)) * centering(rbf(Y, sigma)))\n",
    "\n",
    "\n",
    "def cka(X, Y, sigma=1e-2):\n",
    "        hsic = kernel_HSIC(X, Y, sigma)\n",
    "        var1 = np.sqrt(kernel_HSIC(X, X, sigma))\n",
    "        var2 = np.sqrt(kernel_HSIC(Y, Y, sigma))\n",
    "\n",
    "        return hsic / (var1 * var2)\n",
    "    \n",
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(100, 10)\n",
    "\n",
    "cka_value = cka(X, Y)\n",
    "\n",
    "def objective(Y, X=X, gamma=1e-2):\n",
    "    K_xx = kernel_HSIC(X, X, gamma)\n",
    "    K_yy = kernel_HSIC(Y, Y, gamma)\n",
    "    K_xy = kernel_HSIC(X, Y, gamma)\n",
    "    cka = torch.mean(K_xy) / torch.sqrt(torch.mean(K_xx) * torch.mean(K_yy))\n",
    "    return -cka\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "Y = torch.randn(100, 10, requires_grad=True)\n",
    "optimizer = Adam([Y], lr=1e-2)\n",
    "\n",
    "for i in range(10):\n",
    "    loss = objective(Y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "Y = Y.detach().numpy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Kernel CKA, between diff subset: 0.15928442998902606\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from CKA_utils.CKA import CKA, CudaCKA\n",
    "np_cka = CKA()\n",
    "print('RBF Kernel CKA, between diff subset: {}'.format(np_cka.kernel_CKA(X.detach().numpy(), Y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cka_value = cka(X, torch.Tensor(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999964833259583"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cka_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(100, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.996455729007721"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cka_value = cka(X, Y)\n",
    "cka_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.0000, grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, grad_fn=<RsubBackward1>)\n",
      "tensor(1.0000, grad_fn=<RsubBackward1>)\n"
     ]
    }
   ],
   "source": [
    "####Step 1: Compute the Gram matrices of X and Y using a kernel function. \n",
    "#### The kernel function can be any function that measures the similarity between two inputs. In this case, we will use the Gaussian kernel:\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "def gram_matrix(x, sigma=1):\n",
    "    n = x.size(0)\n",
    "    x = x.view(n, -1)\n",
    "    gram = torch.mm(x, x.t())\n",
    "    gram = torch.exp(-torch.pow(gram, 2) / (2 * sigma**2))\n",
    "    return gram\n",
    "#### Step 2: Compute the centered Gram matrices of X and Y:\n",
    "def centered_gram_matrix(x, sigma=1):\n",
    "    n = x.size(0)\n",
    "    gram = gram_matrix(x, sigma)\n",
    "    ones = torch.ones(n, n) / n\n",
    "    centered_gram = gram - torch.mm(ones, gram) - torch.mm(gram, ones) + torch.mm(ones, torch.mm(gram, ones))\n",
    "    return centered_gram\n",
    "\n",
    "### Step 3: Compute the Hilbert-Schmidt Independence Criterion (HSIC) between X and Y:\n",
    "def hsic(x, y, sigma=1):\n",
    "    x_centered = centered_gram_matrix(x, sigma)\n",
    "    y_centered = centered_gram_matrix(y, sigma)\n",
    "    hsic = torch.trace(torch.mm(x_centered, y_centered))\n",
    "    return hsic\n",
    "#### Step 4: Compute the maximum mean discrepancy (MMD) between X and Y using the same kernel function:\n",
    "def mmd(x, y, sigma=1):\n",
    "    x_gram = gram_matrix(x, sigma)\n",
    "    y_gram = gram_matrix(y, sigma)\n",
    "    mmd = torch.mean(x_gram) - 2 * torch.mean(torch.mm(x_gram, y_gram)) + torch.mean(y_gram)\n",
    "    return mmd\n",
    "### Step5 Step 5: Compute the squared centered kernel alignment (CKA) between X and Y using HSIC and MMD:\n",
    "\n",
    "def cka(x, y, sigma=1):\n",
    "    hsic_xy = hsic(x, y, sigma)\n",
    "    hsic_xx = hsic(x, x, sigma)\n",
    "    hsic_yy = hsic(y, y, sigma)\n",
    "    mmd_xy = mmd(x, y, sigma)\n",
    "    mmd_xx = mmd(x, x, sigma)\n",
    "    mmd_yy = mmd(y, y, sigma)\n",
    "    cka = torch.pow(hsic_xy, 2) / (torch.pow(hsic_xx, 2) * torch.pow(hsic_yy, 2))\n",
    "    cka /= torch.pow(mmd_xy, 2) / (torch.pow(mmd_xx, 2) * torch.pow(mmd_yy, 2))\n",
    "    return cka\n",
    "x = torch.randn(100, 10)\n",
    "y = torch.randn(100, 10)\n",
    "cka_value = cka(x, y)\n",
    "\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.fc(x)\n",
    "        return y\n",
    "\n",
    "class CKALoss(nn.Module):\n",
    "    def __init__(self, sigma=1):\n",
    "        super(CKALoss, self).__init__()\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        x_centered = centered_gram_matrix(x, self.sigma)\n",
    "        y_centered = centered_gram_matrix(y, self.sigma)\n",
    "        hsic_xy = torch.trace(torch.mm(x_centered, y_centered))\n",
    "        hsic_xx = torch.trace(torch.mm(x_centered, x_centered))\n",
    "        hsic_yy = torch.trace(torch.mm(y_centered, y_centered))\n",
    "        mmd_xy = mmd(x, y, self.sigma)\n",
    "        mmd_xx = mmd(x, x, self.sigma)\n",
    "        mmd_yy = mmd(y, y, self.sigma)\n",
    "        cka = torch.pow(hsic_xy, 2) / (torch.pow(hsic_xx, 2) * torch.pow(hsic_yy, 2))\n",
    "        cka /= torch.pow(mmd_xy, 2) / (torch.pow(mmd_xx, 2) * torch.pow(mmd_yy, 2))\n",
    "        loss = 1 - cka\n",
    "        return loss\n",
    "# x = torch.randn(1000, 50)\n",
    "# y = torch.randn(1000, 50)\n",
    "# model = MyModel(10, 10)\n",
    "cka_loss = CKALoss(sigma=1)\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# for epoch in range(100):\n",
    "#     # Forward pass\n",
    "#     y_pred = model(x)\n",
    "#     # Compute CKA loss\n",
    "#     loss = cka_loss(x, y_pred)\n",
    "#     # Backward pass\n",
    "#     optimizer.zero_grad()\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     # Print loss\n",
    "#     print(f\"Epoch [{epoch+1}/{1000}], Loss: {loss.item():.4f}\")\n",
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(100, 10, requires_grad=True)\n",
    "optimizer = Adam([Y], lr=1e-2)\n",
    "\n",
    "for i in range(10):\n",
    "    loss = cka_loss(X, Y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss)\n",
    "\n",
    "Y = Y.detach().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RBF Kernel CKA, between same subset: 0.16438511925374072\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from CKA_utils.CKA import CKA, CudaCKA\n",
    "np_cka = CKA()\n",
    "print('RBF Kernel CKA, between same subset: {}'.format(np_cka.kernel_CKA(X.detach().numpy(), Y.detach().numpy())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5119e-07, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cka(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.9260e-05, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cka(X,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import pdist\n",
    "\n",
    "def rbf_kernel(X, Y, gamma):\n",
    "    X_norms = (X ** 2).sum(dim=1, keepdim=True)\n",
    "    Y_norms = (Y ** 2).sum(dim=1, keepdim=True)\n",
    "    K = torch.exp(-gamma * (X_norms + Y_norms.T - 2 * torch.mm(X, Y.T)))\n",
    "    return K\n",
    "\n",
    "\n",
    "def cka(X, Y, gamma=1e-2):\n",
    "    K_xx = rbf_kernel(X, X, gamma)\n",
    "    K_yy = rbf_kernel(Y, Y, gamma)\n",
    "    K_xy = rbf_kernel(X, Y, gamma)\n",
    "    cka = torch.mean(K_xy) / torch.sqrt(torch.mean(K_xx) * torch.mean(K_yy))\n",
    "    return cka.item()\n",
    "    \n",
    "X = torch.randn(100, 10)\n",
    "Y = torch.randn(100, 10)\n",
    "\n",
    "cka_value = cka(X, Y)\n",
    "\n",
    "def objective(Y, X=X, gamma=1e-2):\n",
    "    K_xx = rbf_kernel(X, X, gamma)\n",
    "    K_yy = rbf_kernel(Y, Y, gamma)\n",
    "    K_xy = rbf_kernel(X, Y, gamma)\n",
    "    cka = torch.mean(K_xy) / torch.sqrt(torch.mean(K_xx) * torch.mean(K_yy))\n",
    "    return -cka\n",
    "\n",
    "from torch.optim import Adam\n",
    "\n",
    "Y = torch.randn(100, 10, requires_grad=True)\n",
    "optimizer = Adam([Y], lr=1e-2)\n",
    "\n",
    "for i in range(1000):\n",
    "    loss = objective(Y)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    print('loss',loss)\n",
    "    optimizer.step()\n",
    "\n",
    "Y = Y.detach().numpy()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "edebc873ae2d93bf61542579b755774a0fcf6e84a6839a73f5ee99d2371b4768"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
