{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yifan/miniconda3/envs/deepdebugger/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish initialization...\n",
      "Finish initialization...\n",
      "Finish initialization...\n",
      "Finish initialization...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import argparse\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "from umap.umap_ import find_ab_params\n",
    "\n",
    "from singleVis.custom_weighted_random_sampler import CustomWeightedRandomSampler\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.losses import UmapLoss, ReconstructionLoss, SingleVisLoss\n",
    "from singleVis.edge_dataset import DataHandler\n",
    "from singleVis.trainer import SingleVisTrainer\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.spatial_edge_constructor import kcSpatialAlignmentEdgeConstructor\n",
    "# from singleVis.temporal_edge_constructor import GlobalTemporalEdgeConstructor\n",
    "from singleVis.alignment_edge_constructor import LocalAlignmentEdgeConstructor\n",
    "from singleVis.projector import TimeVisProjector\n",
    "from singleVis.eval.evaluator import Evaluator\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from CKA import CKA, CudaCKA\n",
    "\n",
    "# REF_PATH : reference dataset path\n",
    "# CONFUSION_PATH : benchmark1\n",
    "# EXCHANGE_PATH : benchmark2\n",
    "\n",
    "REF_PATH = \"/home/yifan/dataset/noisy/pairflip/cifar10/noisy0.001\"\n",
    "CLEAN_PATH = \"/home/yifan/dataset/clean/pairflip/cifar10/0\"\n",
    "\n",
    "CONFUSION_PATH = \"/home/yifan/dataset/confusion/pairflip/cifar10/0\"\n",
    "EXCHANGE_PATH = \"/home/yifan/dataset/exchange/pairflip/cifar10/0\"\n",
    "\n",
    "sys.path.append(REF_PATH)\n",
    "\n",
    "\n",
    "from config import config\n",
    "\n",
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "GPU_ID = config[\"GPU\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "PREPROCESS = VISUALIZATION_PARAMETER[\"PREPROCESS\"]\n",
    "LAMBDA = VISUALIZATION_PARAMETER[\"LAMBDA\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "INIT_NUM = VISUALIZATION_PARAMETER[\"INIT_NUM\"]\n",
    "ALPHA = VISUALIZATION_PARAMETER[\"ALPHA\"]\n",
    "BETA = VISUALIZATION_PARAMETER[\"BETA\"]\n",
    "MAX_HAUSDORFF = VISUALIZATION_PARAMETER[\"MAX_HAUSDORFF\"]\n",
    "# HIDDEN_LAYER = VISUALIZATION_PARAMETER[\"HIDDEN_LAYER\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "T_N_EPOCHS = VISUALIZATION_PARAMETER[\"T_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "VIS_MODEL_NAME = 'vis'\n",
    "EVALUATION_NAME = VISUALIZATION_PARAMETER[\"EVALUATION_NAME\"]\n",
    "\n",
    "SEGMENTS = [(EPOCH_START, EPOCH_END)]\n",
    "# define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))\n",
    "\n",
    "\n",
    "ref_provider = NormalDataProvider(REF_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "clean_provider = NormalDataProvider(CLEAN_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "\n",
    "confusion_provider = NormalDataProvider(CONFUSION_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "\n",
    "exchange_provider = NormalDataProvider(EXCHANGE_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, split=-1, device=DEVICE, classes=CLASSES,verbose=1)\n",
    "\n",
    "\n",
    "ref_train_data = ref_provider.train_representation(200).squeeze()\n",
    "\n",
    "confusion_data = confusion_provider.train_representation(200).squeeze()\n",
    "\n",
    "exchange_data = exchange_provider.train_representation(200).squeeze()\n",
    "\n",
    "clean_data = clean_provider.train_representation(200).squeeze()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 ===  loss:  tensor(2.5099e+13, grad_fn=<DivBackward0>)\n",
      "iteration 10 ===  loss:  tensor(5.0802e+12, grad_fn=<DivBackward0>)\n",
      "iteration 20 ===  loss:  tensor(2.1565e+12, grad_fn=<DivBackward0>)\n",
      "iteration 30 ===  loss:  tensor(1.1921e+12, grad_fn=<DivBackward0>)\n",
      "iteration 40 ===  loss:  tensor(7.5665e+11, grad_fn=<DivBackward0>)\n",
      "iteration 50 ===  loss:  tensor(5.2316e+11, grad_fn=<DivBackward0>)\n",
      "iteration 60 ===  loss:  tensor(3.8341e+11, grad_fn=<DivBackward0>)\n",
      "iteration 70 ===  loss:  tensor(2.9312e+11, grad_fn=<DivBackward0>)\n",
      "iteration 80 ===  loss:  tensor(2.3141e+11, grad_fn=<DivBackward0>)\n",
      "iteration 90 ===  loss:  tensor(1.8735e+11, grad_fn=<DivBackward0>)\n",
      "iteration 100 ===  loss:  tensor(1.5480e+11, grad_fn=<DivBackward0>)\n",
      "iteration 110 ===  loss:  tensor(1.3006e+11, grad_fn=<DivBackward0>)\n",
      "iteration 120 ===  loss:  tensor(1.1082e+11, grad_fn=<DivBackward0>)\n",
      "iteration 130 ===  loss:  tensor(9.5560e+10, grad_fn=<DivBackward0>)\n",
      "iteration 140 ===  loss:  tensor(8.3252e+10, grad_fn=<DivBackward0>)\n",
      "iteration 150 ===  loss:  tensor(7.3181e+10, grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/projects/deepdebugertool/DLVisDebugger/reptransformationHelper/ipykernel_2955500/3230880537.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;31m# X_pred = exchange_provider.get_pred(200, ref_provider.train_representation(200))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;31m# Y_pred = ref_provider.get_pred(200, ref_provider.train_representation(200))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mR1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mR2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malign_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/deepdebugertool/DLVisDebugger/reptransformationHelper/ipykernel_2955500/3230880537.py\u001b[0m in \u001b[0;36malign_embeddings\u001b[0;34m(X, Y, learning_rate, seed)\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"iteration {i} ===  loss: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import scipy\n",
    "import numpy as np\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=REF_PATH, vis_model_name=VIS_MODEL_NAME, device=\"cpu\")\n",
    "\n",
    "# Step2: Computing the loss \n",
    "def compute_gradient(X, Y, R1, R2):\n",
    "    '''\n",
    "        the gradient of the loss with respect to the matrix encodes how much a tiny change \n",
    "    in some coordinate of that matrix affect the change of loss function.\n",
    "        Gradient descent uses that information to iteratively change matrix R until we reach \n",
    "    a point where the loss is minimized.\n",
    "    Inputs: \n",
    "        X: a matrix of dimension (m,n) where the colums are the contrast representation \n",
    "        Y: a matrix of dimension (m,n) where the colums are the reference representation\n",
    "        R: a matrix of dimension (n,n) - transformation matrix from Y2d to X2d\n",
    "    Outputs:\n",
    "       g: a matrix of dimension (n,n) - gradient of the loss function L for given X, Y and R.\n",
    "    '''\n",
    "    # m is the number of rows in X\n",
    "    m = len(X)\n",
    "\n",
    "    rows, columns = X.shape\n",
    "\n",
    "    gradient1 = (np.dot(X.T, np.dot(X, R1) - np.dot(Y, R2)) * 2)/rows\n",
    "    gradient2 = (np.dot(Y.T, np.dot(Y, R2) - np.dot(X, R1)) * 2)/rows\n",
    "\n",
    "    diff = np.dot(X, R1) - np.dot(Y, R2)\n",
    "\n",
    "    # diff_squared is the element-wise square of the difference\n",
    "    diff_squared = diff**2\n",
    "\n",
    "    # sum_diff_squared is the sum of the squared elements\n",
    "    sum_diff_squared = diff_squared.sum()\n",
    "\n",
    "    # loss is the sum_diff_squared divided by the number of examples (m)\n",
    "    loss = sum_diff_squared/m\n",
    "    print(\"loss\",loss)\n",
    "    assert gradient1.shape == (columns, columns)\n",
    "    assert gradient2.shape == (columns, columns)\n",
    "    ### END CODE HERE ###\n",
    "    return gradient1,gradient2\n",
    "\n",
    "def cauculate(X,Y,R):\n",
    "    m = len(X)\n",
    "    Y_2d = projector.batch_project(200, Y)\n",
    "    X_2d = projector.batch_project(200, np.dot(X, R))\n",
    "\n",
    "\n",
    "    Euclid = 0\n",
    "    for i in range(m):\n",
    "        d = ((X_2d[i][0] - Y_2d[i][0])**2 + (X_2d[i][1] - Y_2d[i][1])**2)**0.5\n",
    "        Euclid = Euclid + d\n",
    "    return Euclid/m\n",
    "\n",
    "\n",
    "def regression_loss(x, y):\n",
    "    x = F.normalize(x, dim=1)\n",
    "    y = F.normalize(y, dim=1)\n",
    "    return 2 - 2 * (x * y).sum(dim=-1)\n",
    "# Most of the time we iterate for a fixed number of training steps rather than iterating until the loss falls below a threshold.\n",
    "\n",
    "# 1.Calculate gradient g of the loss with respect to the matrix R. \n",
    "# 2. Update R (Rnew = Rold - αg) . α is the learning rate which is a scalar.\n",
    "\n",
    "# alignment_embeddings\n",
    "\n",
    "def align_embeddings(X: np.ndarray, Y: np.ndarray,\n",
    "                      learning_rate: float=0.0000000003,\n",
    "                      seed: int=129) -> np.ndarray:\n",
    "    '''\n",
    "    Finding the optimal R with gradient descent algorithm\n",
    "    Inputs:\n",
    "        X: a matrix of dimension (m,n) where the colums are the contrast representation \n",
    "        Y: a matrix of dimension (m,n) where the colums are the reference representation\n",
    "        learning_rate: positive float - describes how big steps will  gradient descent algorithm do.\n",
    "    Outputs:\n",
    "        R: a matrix of dimension (n,n) - the projection matrix that minimizes the F norm ||projector(X R) - projector ( Y )||^2\n",
    "    '''\n",
    "    # the number of columns in X is the number of dimensions for a word vector (e.g. 300)\n",
    "    # R is a square matrix with length equal to the number of dimensions in th  word embedding\n",
    "    # R1 = np.random.rand(X.shape[1], X.shape[1])\n",
    "    # R2 = np.random.rand(X.shape[1], X.shape[1])\n",
    "    m = len(X)\n",
    "    R1 = Variable(torch.ones(X.shape[1],X.shape[1]),requires_grad=True)\n",
    "    R2 = Variable(torch.ones(X.shape[1],X.shape[1]),requires_grad=True)\n",
    "    # R = Variable(torch.ones(X.shape[1],X.shape[1]),requires_grad=True)\n",
    "    X = torch.Tensor(X)\n",
    "    Y = torch.Tensor(Y)\n",
    "        \n",
    "    train_steps = 6000\n",
    "    for i in range(train_steps):\n",
    "\n",
    "    \n",
    "        loss = ((( X.matmul(R1).matmul(R2) - Y)**2).sum())/m\n",
    "        if i%10 == 0:\n",
    "            print(f\"iteration {i} ===  loss: \",loss) \n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        # lossCON = loss + lossFn\n",
    "        # lossCON.backward()\n",
    "        # grad = (np.dot(X.detach().numpy().T, np.dot(X.detach().numpy(), R.detach().numpy()) - Y.detach().numpy()) * 2)/rows\n",
    "\n",
    "        R1.data = R1.data - learning_rate * R1.grad.data\n",
    "        R2.data = R2.data - learning_rate * R2.grad.data\n",
    "        ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "        # use the function that you defined to compute the gradient\n",
    "        R1.grad.data.zero_()\n",
    "        R2.grad.data.zero_()\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    return R1, R2\n",
    "\n",
    "# np.random.seed(129)\n",
    "# m = 10\n",
    "# n = 5\n",
    "X = confusion_data\n",
    "Y = ref_train_data\n",
    "\n",
    "# X_pred = exchange_provider.get_pred(200, ref_provider.train_representation(200))\n",
    "# Y_pred = ref_provider.get_pred(200, ref_provider.train_representation(200))\n",
    "R1, R2 = align_embeddings(X, Y)\n",
    "\n",
    "\n",
    "print(R1)\n",
    "import time\n",
    "import json\n",
    "filename = now = time.strftime(\"confusion_dataR1R2_ref_R1.json\", time.localtime(time.time())) \n",
    "rlist = json.dumps(R1.tolist())\n",
    "with open(filename, 'w', encoding='utf-8') as file_obj:\n",
    "\n",
    "    file_obj.write(rlist)\n",
    "\n",
    "filename2 = now = time.strftime(\"confusion_dataR1R2_ref_R2.json\", time.localtime(time.time())) \n",
    "rlist = json.dumps(R2.tolist())\n",
    "with open(filename2, 'w', encoding='utf-8') as file_obj:\n",
    "\n",
    "    file_obj.write(rlist)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepdebugger",
   "language": "python",
   "name": "deepdebugger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
